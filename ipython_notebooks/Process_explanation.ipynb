{
 "metadata": {
  "name": "",
  "signature": "sha256:6d14f92bdff26eefbe3be93f0262e35304958ddcab6570dd624168a2d5567e61"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "PLOS Cloud Explorer: The Process"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook is about our process for figuring out what PLOS Cloud Explorer was going to be. It includes early code, prototypes, and dead ends.\n",
      "\n",
      "For the full story including the happy ending, read [this document](https://github.com/cmgerber/PLOS_Cloud_Explorer/blob/master/README.md) and follow the other notebook links to see the code we actually used."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First things first. All imports for this notebook:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import unicode_literals\n",
      "\n",
      "# You need an API Key for PLOS\n",
      "import settings\n",
      "\n",
      "# Data analysis\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from numpy import nan\n",
      "from pandas import Series, DataFrame\n",
      "\n",
      "# Interacting with API\n",
      "import requests\n",
      "import urllib\n",
      "import time\n",
      "from retrying import retry\n",
      "import os\n",
      "import random\n",
      "import json\n",
      "\n",
      "# Natural language processing\n",
      "import nltk\n",
      "from nltk.collocations import BigramCollocationFinder\n",
      "from nltk.metrics import BigramAssocMeasures\n",
      "from nltk.corpus import stopwords\n",
      "import string\n",
      "\n",
      "# For the IPython widgets:\n",
      "from IPython.display import display, Image, HTML, clear_output\n",
      "from IPython.html import widgets\n",
      "from jinja2 import Template"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data Collection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We began with a really simple way of getting article data from the PLOS Search API:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = requests.get('http://api.plos.org/search?q=subject:\"biotechnology\"&start=0&rows=500&api_key={%s}&wt=json' % settings.PLOS_KEY).json()\n",
      "len(r['response']['docs'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "500"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write out a file.\n",
      "with open('biotech500.json', 'wb') as fp:\n",
      "    json.dump(r, fp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We later developed a much more sophisticated way to get huge amounts of data from the API. To see how we collected data sets, see the \n",
      "[batch data collection notebook](http://nbviewer.ipython.org/github/cmgerber/PLOS_Cloud_Explorer/blob/master/ipython_notebooks/Batch_data_collection_full.ipynb)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exploring Output"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we show what the output looks like, from a previously run API query. Through the magic of Python, we can pickle the resulting DataFrame and access it again now without making any API calls."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abstract_df = pd.read_pickle('../data/abstract_df.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(list(abstract_df.author))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "1120"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print list(abstract_df.subject)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'/Computer and information sciences/Information technology/Data processing', u'/Computer and information sciences/Information technology/Data reduction', u'/Physical sciences/Mathematics/Statistics (mathematics)/Statistical methods', u'/Research and analysis methods/Mathematical and statistical techniques/Statistical methods', u'/Computer and information sciences/Information technology/Databases', u'/Physical sciences/Mathematics/Statistics (mathematics)/Statistical data', u'/Computer and information sciences/Computer architecture/User interfaces', u'/Medicine and health sciences/Infectious diseases/Infectious disease control', u'/Computer and information sciences/Data management']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abstract_df.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>author</th>\n",
        "      <th>id</th>\n",
        "      <th>journal</th>\n",
        "      <th>publication_date</th>\n",
        "      <th>score</th>\n",
        "      <th>subject</th>\n",
        "      <th>title_display</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> [\\nPopulation structure can confound the ident...</td>\n",
        "      <td> [Jonathan Carlson, Carl Kadie, Simon Mallal, D...</td>\n",
        "      <td> 10.1371/journal.pone.0000591</td>\n",
        "      <td>                   PLoS ONE</td>\n",
        "      <td> 2007-07-04T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Biology and life sciences/Genetics/Phenotype...</td>\n",
        "      <td> Leveraging Hierarchical Population Structure i...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> [\\n        The discrimination of thatcherized ...</td>\n",
        "      <td> [Nick Donnelly, Nicole R Z\u00fcrcher, Katherine Co...</td>\n",
        "      <td> 10.1371/journal.pone.0023340</td>\n",
        "      <td>                   PLoS ONE</td>\n",
        "      <td> 2011-08-31T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Medicine and health sciences/Diagnostic medi...</td>\n",
        "      <td> Discriminating Grotesque from Typical Faces: E...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> [\\nInfluenza viruses have been responsible for...</td>\n",
        "      <td>           [Zhipeng Cai, Tong Zhang, Xiu-Feng Wan]</td>\n",
        "      <td> 10.1371/journal.pcbi.1000949</td>\n",
        "      <td> PLoS Computational Biology</td>\n",
        "      <td> 2010-10-07T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Biology and life sciences/Organisms/Viruses/...</td>\n",
        "      <td> A Computational Framework for Influenza Antige...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td> [\\n        Based on previous evidence for indi...</td>\n",
        "      <td> [Luis F H Basile, Jo\u00e3o R Sato, Milkes Y Alvare...</td>\n",
        "      <td> 10.1371/journal.pone.0059595</td>\n",
        "      <td>                   PLoS ONE</td>\n",
        "      <td> 2013-03-27T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Medicine and health sciences/Diagnostic medi...</td>\n",
        "      <td> Lack of Systematic Topographic Difference betw...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> [Objective: Herpes simplex virus type 2 (HSV-2...</td>\n",
        "      <td> [Alison C Roxby, Alison L Drake, Francisca Ong...</td>\n",
        "      <td> 10.1371/journal.pone.0038622</td>\n",
        "      <td>                   PLoS ONE</td>\n",
        "      <td> 2012-06-12T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Medicine and health sciences/Women's health/...</td>\n",
        "      <td> Effects of Valacyclovir on Markers of Disease ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 8 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "                                             abstract  \\\n",
        "15  [\\nPopulation structure can confound the ident...   \n",
        "16  [\\n        The discrimination of thatcherized ...   \n",
        "17  [\\nInfluenza viruses have been responsible for...   \n",
        "18  [\\n        Based on previous evidence for indi...   \n",
        "19  [Objective: Herpes simplex virus type 2 (HSV-2...   \n",
        "\n",
        "                                               author  \\\n",
        "15  [Jonathan Carlson, Carl Kadie, Simon Mallal, D...   \n",
        "16  [Nick Donnelly, Nicole R Z\u00fcrcher, Katherine Co...   \n",
        "17            [Zhipeng Cai, Tong Zhang, Xiu-Feng Wan]   \n",
        "18  [Luis F H Basile, Jo\u00e3o R Sato, Milkes Y Alvare...   \n",
        "19  [Alison C Roxby, Alison L Drake, Francisca Ong...   \n",
        "\n",
        "                              id                     journal  \\\n",
        "15  10.1371/journal.pone.0000591                    PLoS ONE   \n",
        "16  10.1371/journal.pone.0023340                    PLoS ONE   \n",
        "17  10.1371/journal.pcbi.1000949  PLoS Computational Biology   \n",
        "18  10.1371/journal.pone.0059595                    PLoS ONE   \n",
        "19  10.1371/journal.pone.0038622                    PLoS ONE   \n",
        "\n",
        "        publication_date     score  \\\n",
        "15  2007-07-04T00:00:00Z  0.443733   \n",
        "16  2011-08-31T00:00:00Z  0.443733   \n",
        "17  2010-10-07T00:00:00Z  0.443733   \n",
        "18  2013-03-27T00:00:00Z  0.443733   \n",
        "19  2012-06-12T00:00:00Z  0.443733   \n",
        "\n",
        "                                              subject  \\\n",
        "15  [/Biology and life sciences/Genetics/Phenotype...   \n",
        "16  [/Medicine and health sciences/Diagnostic medi...   \n",
        "17  [/Biology and life sciences/Organisms/Viruses/...   \n",
        "18  [/Medicine and health sciences/Diagnostic medi...   \n",
        "19  [/Medicine and health sciences/Women's health/...   \n",
        "\n",
        "                                        title_display  \n",
        "15  Leveraging Hierarchical Population Structure i...  \n",
        "16  Discriminating Grotesque from Typical Faces: E...  \n",
        "17  A Computational Framework for Influenza Antige...  \n",
        "18  Lack of Systematic Topographic Difference betw...  \n",
        "19  Effects of Valacyclovir on Markers of Disease ...  \n",
        "\n",
        "[5 rows x 8 columns]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Initial attempts to make word clouds using abstracts"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We wanted to use basic natural language processing (NLP) to make word clouds out of aggregated abstract text, and see how they change over time.\n",
      "\n",
      "NB: These examples use a previously collected dataset that's different and smaller than the one we generated above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Globally define a set of stopwords.\n",
      "stops = set(stopwords.words('english'))\n",
      "# We can add science-y stuff to it as well. Just an example:\n",
      "stops.add('conclusions')\n",
      "\n",
      "\n",
      "def wordify(abs_list, min_word_len=2):\n",
      "    '''\n",
      "    Convert the abstract field from PLoS API data to a filtered list of words.\n",
      "    '''\n",
      "\n",
      "    # The abstract field is a list. Make it a string.\n",
      "    text = ' '.join(abs_list).strip(' \\n\\t')\n",
      "\n",
      "    if text == '':\n",
      "        return nan\n",
      "\n",
      "    else:\n",
      "        # Remove punctuation & replace with space,\n",
      "        # because we want 'metal-contaminated' => 'metal contaminated'\n",
      "        # ...not 'metalcontaminated', and so on.\n",
      "        for c in string.punctuation:\n",
      "            text = text.replace(c, ' ')\n",
      "\n",
      "        # Now make it a Series of words, and do some cleaning.\n",
      "        words = Series(text.split(' '))\n",
      "        words = words.str.lower()\n",
      "        # Filter out words less than minimum word length.\n",
      "        words = words[words.str.len() >= min_word_len]\n",
      "        words = words[~words.str.contains(r'[^#@a-z]')]  # What exactly does this do?\n",
      "\n",
      "        # Filter out globally-defined stopwords\n",
      "        ignore = stops & set(words.unique())\n",
      "        words_out = [w for w in words.tolist() if w not in ignore]\n",
      "\n",
      "        return words_out\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load up some data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('biotech500.json', 'rb') as fp:\n",
      "    data = json.load(fp)\n",
      "    \n",
      "articles_list = data['response']['docs']\n",
      "articles = DataFrame(articles_list)\n",
      "articles = articles[articles['abstract'].notnull()]\n",
      "articles.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>article_type</th>\n",
        "      <th>author_display</th>\n",
        "      <th>eissn</th>\n",
        "      <th>id</th>\n",
        "      <th>journal</th>\n",
        "      <th>publication_date</th>\n",
        "      <th>score</th>\n",
        "      <th>title_display</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> [\\nThe objective of this paper is to assess th...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Latifah Amin, Md. Abul Kalam Azad, Mohd Hanaf...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0086174</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2014-01-29T00:00:00Z</td>\n",
        "      <td> 1.211935</td>\n",
        "      <td> Determinants of Public Attitudes to Geneticall...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> [\\n        Atrazine (ATZ) and S-metolachlor (S...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Cristina A. Viegas, Catarina Costa, Sandra An...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0037140</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2012-05-15T00:00:00Z</td>\n",
        "      <td> 1.119538</td>\n",
        "      <td> Does &lt;i&gt;S&lt;/i&gt;-Metolachlor Affect the Performan...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> [\\nDue to environmental persistence and biotox...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Yonggang Yang, Meiying Xu, Zhili He, Jun Guo,...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0070686</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2013-08-05T00:00:00Z</td>\n",
        "      <td> 1.119538</td>\n",
        "      <td> Microbial Electricity Generation Enhances Deca...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td> [\\n        Intensive use of chlorpyrifos has r...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Shaohua Chen, Chenglan Liu, Chuyan Peng, Hong...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0047205</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 2012-10-08T00:00:00Z</td>\n",
        "      <td> 1.119538</td>\n",
        "      <td> Biodegradation of Chlorpyrifos and Its Hydroly...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td> [Background: The complex characteristics and u...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Zhongbo Zhou, Fangang Meng, So-Ryong Chae, Gu...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0042270</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 2012-08-09T00:00:00Z</td>\n",
        "      <td> 0.989541</td>\n",
        "      <td> Microbial Transformation of Biomacromolecules ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 9 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "                                             abstract      article_type  \\\n",
        "7   [\\nThe objective of this paper is to assess th...  Research Article   \n",
        "16  [\\n        Atrazine (ATZ) and S-metolachlor (S...  Research Article   \n",
        "17  [\\nDue to environmental persistence and biotox...  Research Article   \n",
        "34  [\\n        Intensive use of chlorpyrifos has r...  Research Article   \n",
        "35  [Background: The complex characteristics and u...  Research Article   \n",
        "\n",
        "                                       author_display      eissn  \\\n",
        "7   [Latifah Amin, Md. Abul Kalam Azad, Mohd Hanaf...  1932-6203   \n",
        "16  [Cristina A. Viegas, Catarina Costa, Sandra An...  1932-6203   \n",
        "17  [Yonggang Yang, Meiying Xu, Zhili He, Jun Guo,...  1932-6203   \n",
        "34  [Shaohua Chen, Chenglan Liu, Chuyan Peng, Hong...  1932-6203   \n",
        "35  [Zhongbo Zhou, Fangang Meng, So-Ryong Chae, Gu...  1932-6203   \n",
        "\n",
        "                              id   journal      publication_date     score  \\\n",
        "7   10.1371/journal.pone.0086174  PLoS ONE  2014-01-29T00:00:00Z  1.211935   \n",
        "16  10.1371/journal.pone.0037140  PLoS ONE  2012-05-15T00:00:00Z  1.119538   \n",
        "17  10.1371/journal.pone.0070686  PLoS ONE  2013-08-05T00:00:00Z  1.119538   \n",
        "34  10.1371/journal.pone.0047205       NaN  2012-10-08T00:00:00Z  1.119538   \n",
        "35  10.1371/journal.pone.0042270       NaN  2012-08-09T00:00:00Z  0.989541   \n",
        "\n",
        "                                        title_display  \n",
        "7   Determinants of Public Attitudes to Geneticall...  \n",
        "16  Does <i>S</i>-Metolachlor Affect the Performan...  \n",
        "17  Microbial Electricity Generation Enhances Deca...  \n",
        "34  Biodegradation of Chlorpyrifos and Its Hydroly...  \n",
        "35  Microbial Transformation of Biomacromolecules ...  \n",
        "\n",
        "[5 rows x 9 columns]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Applying this to the whole DataFrame of articles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles['words'] = articles.apply(lambda s: wordify(s['abstract'] + [s['title_display']]), axis=1)\n",
      "articles.drop(['article_type', 'score', 'title_display', 'abstract'], axis=1, inplace=True)\n",
      "articles.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>author_display</th>\n",
        "      <th>eissn</th>\n",
        "      <th>id</th>\n",
        "      <th>journal</th>\n",
        "      <th>publication_date</th>\n",
        "      <th>words</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> [Latifah Amin, Md. Abul Kalam Azad, Mohd Hanaf...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0086174</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2014-01-29T00:00:00Z</td>\n",
        "      <td> [objective, paper, assess, attitude, malaysian...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> [Cristina A. Viegas, Catarina Costa, Sandra An...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0037140</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2012-05-15T00:00:00Z</td>\n",
        "      <td> [atrazine, atz, metolachlor, met, two, herbici...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> [Yonggang Yang, Meiying Xu, Zhili He, Jun Guo,...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0070686</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2013-08-05T00:00:00Z</td>\n",
        "      <td> [due, environmental, persistence, biotoxicity,...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td> [Shaohua Chen, Chenglan Liu, Chuyan Peng, Hong...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0047205</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 2012-10-08T00:00:00Z</td>\n",
        "      <td> [intensive, use, chlorpyrifos, resulted, ubiqu...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td> [Zhongbo Zhou, Fangang Meng, So-Ryong Chae, Gu...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0042270</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 2012-08-09T00:00:00Z</td>\n",
        "      <td> [background, complex, characteristics, unclear...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 6 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "                                       author_display      eissn  \\\n",
        "7   [Latifah Amin, Md. Abul Kalam Azad, Mohd Hanaf...  1932-6203   \n",
        "16  [Cristina A. Viegas, Catarina Costa, Sandra An...  1932-6203   \n",
        "17  [Yonggang Yang, Meiying Xu, Zhili He, Jun Guo,...  1932-6203   \n",
        "34  [Shaohua Chen, Chenglan Liu, Chuyan Peng, Hong...  1932-6203   \n",
        "35  [Zhongbo Zhou, Fangang Meng, So-Ryong Chae, Gu...  1932-6203   \n",
        "\n",
        "                              id   journal      publication_date  \\\n",
        "7   10.1371/journal.pone.0086174  PLoS ONE  2014-01-29T00:00:00Z   \n",
        "16  10.1371/journal.pone.0037140  PLoS ONE  2012-05-15T00:00:00Z   \n",
        "17  10.1371/journal.pone.0070686  PLoS ONE  2013-08-05T00:00:00Z   \n",
        "34  10.1371/journal.pone.0047205       NaN  2012-10-08T00:00:00Z   \n",
        "35  10.1371/journal.pone.0042270       NaN  2012-08-09T00:00:00Z   \n",
        "\n",
        "                                                words  \n",
        "7   [objective, paper, assess, attitude, malaysian...  \n",
        "16  [atrazine, atz, metolachlor, met, two, herbici...  \n",
        "17  [due, environmental, persistence, biotoxicity,...  \n",
        "34  [intensive, use, chlorpyrifos, resulted, ubiqu...  \n",
        "35  [background, complex, characteristics, unclear...  \n",
        "\n",
        "[5 rows x 6 columns]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Doing some natural language processing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abs_df = DataFrame(articles['words'].apply(lambda x: ' '.join(x)).tolist(), columns=['text'])\n",
      "abs_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> objective paper assess attitude malaysian stak...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> atrazine atz metolachlor met two herbicides wi...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> due environmental persistence biotoxicity poly...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> intensive use chlorpyrifos resulted ubiquitous...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> background complex characteristics unclear bio...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "                                                text\n",
        "0  objective paper assess attitude malaysian stak...\n",
        "1  atrazine atz metolachlor met two herbicides wi...\n",
        "2  due environmental persistence biotoxicity poly...\n",
        "3  intensive use chlorpyrifos resulted ubiquitous...\n",
        "4  background complex characteristics unclear bio...\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Common word pairs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section uses all words from abstracts to find the common word pairs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#include all words from abstracts for getting common word pairs\n",
      "words_all = pd.Series(' '.join(abs_df['text']).split(' '))\n",
      "words_all.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "study             56\n",
        "using             33\n",
        "two               32\n",
        "patients          31\n",
        "biodegradation    30\n",
        "non               29\n",
        "data              28\n",
        "three             28\n",
        "analysis          27\n",
        "compared          27\n",
        "soil              27\n",
        "new               27\n",
        "results           26\n",
        "species           25\n",
        "cell              25\n",
        "...\n",
        "engage             1\n",
        "thermal            1\n",
        "geochip            1\n",
        "dominant           1\n",
        "suggests           1\n",
        "third              1\n",
        "usually            1\n",
        "locomotion         1\n",
        "rpos               1\n",
        "scales             1\n",
        "prefer             1\n",
        "quite              1\n",
        "protocatechuate    1\n",
        "routine            1\n",
        "agr                1\n",
        "Length: 3028, dtype: int64"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "relevant_words_pairs = words_all.copy()\n",
      "relevant_words_pairs.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "study             56\n",
        "using             33\n",
        "two               32\n",
        "patients          31\n",
        "biodegradation    30\n",
        "non               29\n",
        "data              28\n",
        "three             28\n",
        "analysis          27\n",
        "compared          27\n",
        "soil              27\n",
        "new               27\n",
        "results           26\n",
        "species           25\n",
        "cell              25\n",
        "...\n",
        "engage             1\n",
        "thermal            1\n",
        "geochip            1\n",
        "dominant           1\n",
        "suggests           1\n",
        "third              1\n",
        "usually            1\n",
        "locomotion         1\n",
        "rpos               1\n",
        "scales             1\n",
        "prefer             1\n",
        "quite              1\n",
        "protocatechuate    1\n",
        "routine            1\n",
        "agr                1\n",
        "Length: 3028, dtype: int64"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bcf = BigramCollocationFinder.from_words(relevant_words_pairs)\n",
      "for pair in bcf.nbest(BigramAssocMeasures.likelihood_ratio, 30):\n",
      "    print ' '.join(pair)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synthetic biology\n",
        "spider silk\n",
        "es cell\n",
        "adjacent segment\n",
        "medical imaging\n",
        "dp dtmax\n",
        "security privacy\n",
        "industry backgrounds\n",
        "removal initiation\n",
        "uv irradiated\n",
        "gm salmon\n",
        "persistent crsab\n",
        "antimicrobial therapy\n",
        "limb amputation\n",
        "cellular phone\n",
        "wireless powered\n",
        "minimally invasive\n",
        "phone technology\n",
        "heavy metals\n",
        "battery powered\n",
        "composite mesh\n",
        "frequency currents\n",
        "genetically modified\n",
        "tissue engineering\n",
        "catheter removal\n",
        "acting reversible\n",
        "brassica napus\n",
        "brown streak\n",
        "quasi stiffness\n",
        "data code\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bcf.nbest(BigramAssocMeasures.likelihood_ratio, 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[(u'synthetic', u'biology'),\n",
        " (u'spider', u'silk'),\n",
        " (u'es', u'cell'),\n",
        " (u'adjacent', u'segment'),\n",
        " (u'medical', u'imaging'),\n",
        " (u'dp', u'dtmax'),\n",
        " (u'security', u'privacy'),\n",
        " (u'industry', u'backgrounds'),\n",
        " (u'removal', u'initiation'),\n",
        " (u'uv', u'irradiated'),\n",
        " (u'gm', u'salmon'),\n",
        " (u'persistent', u'crsab'),\n",
        " (u'antimicrobial', u'therapy'),\n",
        " (u'limb', u'amputation'),\n",
        " (u'cellular', u'phone'),\n",
        " (u'wireless', u'powered'),\n",
        " (u'minimally', u'invasive'),\n",
        " (u'phone', u'technology'),\n",
        " (u'heavy', u'metals'),\n",
        " (u'battery', u'powered')]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Making word clouds: select the top words"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we takes only unique words from each abstract."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abs_set_df = DataFrame(articles['words'].apply(lambda x: ' '.join(set(x))).tolist(), columns=['text'])\n",
      "abs_set_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> among developed attitude paper identify accept...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> aquatic mineralization dose experiments still ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> mfc hypothesized distinctly results nitrogen s...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> fungal contaminant tcp accumulative gc morphol...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> origin humic mineralization show mainly result...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "                                                text\n",
        "0  among developed attitude paper identify accept...\n",
        "1  aquatic mineralization dose experiments still ...\n",
        "2  mfc hypothesized distinctly results nitrogen s...\n",
        "3  fungal contaminant tcp accumulative gc morphol...\n",
        "4  origin humic mineralization show mainly result...\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = pd.Series(' '.join(abs_set_df['text']).split(' '))\n",
      "words.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "study            38\n",
        "two              23\n",
        "using            21\n",
        "results          20\n",
        "three            20\n",
        "analysis         20\n",
        "compared         17\n",
        "used             16\n",
        "higher           16\n",
        "may              16\n",
        "non              15\n",
        "based            15\n",
        "significantly    14\n",
        "also             14\n",
        "however          14\n",
        "...\n",
        "septal             1\n",
        "recommendations    1\n",
        "genomes            1\n",
        "poking             1\n",
        "gck                1\n",
        "optimised          1\n",
        "varied             1\n",
        "counting           1\n",
        "monitoring         1\n",
        "malware            1\n",
        "tmc                1\n",
        "rape               1\n",
        "occur              1\n",
        "conversely         1\n",
        "cda                1\n",
        "Length: 3028, dtype: int64"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_words = words.value_counts().reset_index()\n",
      "top_words.columns = ['word', 'count']\n",
      "top_words.head(15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>word</th>\n",
        "      <th>count</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>         study</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>           two</td>\n",
        "      <td> 23</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>         using</td>\n",
        "      <td> 21</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>       results</td>\n",
        "      <td> 20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>         three</td>\n",
        "      <td> 20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>      analysis</td>\n",
        "      <td> 20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>      compared</td>\n",
        "      <td> 17</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>          used</td>\n",
        "      <td> 16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>        higher</td>\n",
        "      <td> 16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>           may</td>\n",
        "      <td> 16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>           non</td>\n",
        "      <td> 15</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>         based</td>\n",
        "      <td> 15</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> significantly</td>\n",
        "      <td> 14</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>          also</td>\n",
        "      <td> 14</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>       however</td>\n",
        "      <td> 14</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>15 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "             word  count\n",
        "0           study     38\n",
        "1             two     23\n",
        "2           using     21\n",
        "3         results     20\n",
        "4           three     20\n",
        "5        analysis     20\n",
        "6        compared     17\n",
        "7            used     16\n",
        "8          higher     16\n",
        "9             may     16\n",
        "10            non     15\n",
        "11          based     15\n",
        "12  significantly     14\n",
        "13           also     14\n",
        "14        however     14\n",
        "\n",
        "[15 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Exporting word count data as CSV for D3 word-cloudification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# top_words.to_csv('../wordcloud2.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Initial word cloud results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When we created the word clouds, we noticed something about the most common words in these article abstracts... \n",
      "\n",
      "![cloud](../wordcloud_example_old.jpg)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Change over time: working with article abstracts as time series data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_list = data['response']['docs']\n",
      "articles = DataFrame(articles_list)\n",
      "articles = articles[articles['abstract'].notnull()].ix[:,['abstract', 'publication_date']]\n",
      "articles.abstract = articles.abstract.apply(wordify, 3)\n",
      "articles = articles[articles['abstract'].notnull()]\n",
      "articles.publication_date = pd.to_datetime(articles.publication_date)\n",
      "articles.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>publication_date</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> [objective, paper, assess, attitude, malaysian...</td>\n",
        "      <td>2014-01-29</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> [atrazine, atz, metolachlor, met, two, herbici...</td>\n",
        "      <td>2012-05-15</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> [due, environmental, persistence, biotoxicity,...</td>\n",
        "      <td>2013-08-05</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td> [intensive, use, chlorpyrifos, resulted, ubiqu...</td>\n",
        "      <td>2012-10-08</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td> [background, complex, characteristics, unclear...</td>\n",
        "      <td>2012-08-09</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "                                             abstract publication_date\n",
        "7   [objective, paper, assess, attitude, malaysian...       2014-01-29\n",
        "16  [atrazine, atz, metolachlor, met, two, herbici...       2012-05-15\n",
        "17  [due, environmental, persistence, biotoxicity,...       2013-08-05\n",
        "34  [intensive, use, chlorpyrifos, resulted, ubiqu...       2012-10-08\n",
        "35  [background, complex, characteristics, unclear...       2012-08-09\n",
        "\n",
        "[5 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print articles.publication_date.min(), articles.publication_date.max()\n",
      "print len(articles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2008-04-30 00:00:00 2014-04-11 00:00:00\n",
        "57\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The time series spans ~9 years with 57 data points. **We need to resample!**\n",
      "\n",
      "There are probably many ways to do this..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_timed = articles.set_index('publication_date')\n",
      "articles_timed.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>publication_date</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2014-01-29</th>\n",
        "      <td> [objective, paper, assess, attitude, malaysian...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2012-05-15</th>\n",
        "      <td> [atrazine, atz, metolachlor, met, two, herbici...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013-08-05</th>\n",
        "      <td> [due, environmental, persistence, biotoxicity,...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2012-10-08</th>\n",
        "      <td> [intensive, use, chlorpyrifos, resulted, ubiqu...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2012-08-09</th>\n",
        "      <td> [background, complex, characteristics, unclear...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "                                                           abstract\n",
        "publication_date                                                   \n",
        "2014-01-29        [objective, paper, assess, attitude, malaysian...\n",
        "2012-05-15        [atrazine, atz, metolachlor, met, two, herbici...\n",
        "2013-08-05        [due, environmental, persistence, biotoxicity,...\n",
        "2012-10-08        [intensive, use, chlorpyrifos, resulted, ubiqu...\n",
        "2012-08-09        [background, complex, characteristics, unclear...\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Using pandas time series resampling functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the `sum` aggregation method works because all the values were lists. The three abstracts published in 2013-05 were concatenated together (see below)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_monthly = articles_timed.resample('M', how='sum', fill_method='ffill', kind='period')\n",
      "articles_monthly.abstract = articles_monthly.abstract.apply(lambda x: np.nan if x == 0 else x)\n",
      "articles_monthly.fillna(method='ffill', inplace=True)\n",
      "articles_monthly.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>publication_date</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2008-04</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008-05</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008-06</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008-07</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008-08</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "                                                           abstract\n",
        "publication_date                                                   \n",
        "2008-04           [according, world, health, organization, repor...\n",
        "2008-05           [according, world, health, organization, repor...\n",
        "2008-06           [according, world, health, organization, repor...\n",
        "2008-07           [according, world, health, organization, repor...\n",
        "2008-08           [according, world, health, organization, repor...\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Making a time slider for abstract text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "widgetmax = len(articles_monthly) - 1\n",
      "\n",
      "def textbarf(t): \n",
      "    html_template = \"\"\"\n",
      "    <style>\n",
      "    #textbarf {\n",
      "        display: block;\n",
      "        width: 666px;\n",
      "        padding: 23px;\n",
      "        background-color: #ddeeff;\n",
      "    }\n",
      "    </style>\n",
      "    <div id=\"textbarf\"> {{blargh}} </div>\"\"\"\n",
      "\n",
      "    blob = ' '.join(articles_monthly.ix[t]['abstract'])\n",
      "    html_src = Template(html_template).render(blargh=blob)\n",
      "    display(HTML(html_src))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "widgets.interact(textbarf,\n",
      "                 t=widgets.IntSliderWidget(min=0,max=widgetmax,step=1,value=42),\n",
      "                )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "    <style>\n",
        "    #textbarf {\n",
        "        display: block;\n",
        "        width: 666px;\n",
        "        padding: 23px;\n",
        "        background-color: #ddeeff;\n",
        "    }\n",
        "    </style>\n",
        "    <div id=\"textbarf\"> concerns regarding commercial release genetically engineered ge crops include naturalization introgression sexually compatible relatives transfer beneficial traits native weedy species hybridization date documented reports escape leading researchers question environmental risks biotech products study conducted systematic roadside survey canola brassica napus populations growing outside cultivation north dakota usa dominant canola growing region document presence two escaped transgenic genotypes well non ge canola provide evidence novel combinations transgenic forms wild results demonstrate feral populations large widespread moreover flowering times escaped populations well fertile condition majority collections suggest populations established persistent outside cultivation </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x1099400d0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "<function __main__.textbarf>"
       ]
      }
     ],
     "prompt_number": 29
    }
   ],
   "metadata": {}
  }
 ]
}