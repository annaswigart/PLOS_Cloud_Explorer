{
 "metadata": {
  "name": "",
  "signature": "sha256:f434b767d37d3c4fadb65945756cdb9f2ce58f9d55275d38395dba915b233993"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "PLOS Cloud Explorer: The Process"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First things first. All imports for this notebook:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import unicode_literals\n",
      "\n",
      "# Data analysis\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from numpy import nan\n",
      "from pandas import Series, DataFrame\n",
      "import xlrd\n",
      "from collections import defaultdict\n",
      "\n",
      "# You need an API Key for PLOS\n",
      "import settings\n",
      "\n",
      "# Interacting with API\n",
      "import requests\n",
      "import urllib\n",
      "import time\n",
      "from retrying import retry\n",
      "import os\n",
      "import random\n",
      "import json\n",
      "\n",
      "# Natural language processing\n",
      "import nltk\n",
      "from nltk.collocations import BigramCollocationFinder\n",
      "from nltk.metrics import BigramAssocMeasures\n",
      "from nltk.corpus import stopwords\n",
      "import string\n",
      "\n",
      "# For the IPython widgets:\n",
      "from IPython.display import display, Image, HTML, clear_output\n",
      "from IPython.html import widgets\n",
      "from jinja2 import Template"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Batch Data Collection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We needed to collect article data from the PLOS API, which would include\n",
      "\n",
      "* article titles, authors, DOIs\n",
      "* publication date\n",
      "* abstracts\n",
      "* subject areas\n",
      "\n",
      "The code below will download all 100k+ articles with abstracts from the PLOS API, while respecting the limits on the frequency and number of API calls.\n",
      "\n",
      "We ended up downloading and saving data on articles within the subject area \"Information Technology.\"\n",
      "\n",
      "*See below for sections describing subsequent the data analysis.*"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "API Call Function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#adapted from Raymond's notebook\n",
      "\n",
      "def plos_search(q,start=0,rows=100,fl=None, extras=None):\n",
      "\n",
      "    BASE_URL = 'http://api.plos.org/search'\n",
      "    DEFAULT_FL = ('abstract','author',\n",
      "                  'id','journal','publication_date',\n",
      "                  'score','title_display', 'subject','subject_level')\n",
      "        #removed elements: eissn, article_type\n",
      "    \n",
      "    # fl indicates fields to return\n",
      "    # http://wiki.apache.org/solr/CommonQueryParameters#fl\n",
      "    \n",
      "    if fl is None:\n",
      "        fl_ = \",\".join(DEFAULT_FL)\n",
      "    else:\n",
      "        fl_ = \",\".join(fl)\n",
      "        \n",
      "    query = {'q':q,\n",
      "             'start':start,\n",
      "             'rows':rows,\n",
      "             'api_key':settings.PLOS_KEY,\n",
      "             'wt':'json',\n",
      "             'fl':fl_,\n",
      "             'fq': 'doc_type:full AND !article_type_facet:\"Issue Image\"'}\n",
      "    \n",
      "    if extras is not None:\n",
      "        query.update(extras)\n",
      "        \n",
      "    query_url = BASE_URL + \"?\" +urllib.urlencode(query)\n",
      "    \n",
      "    r = requests.get(query_url)\n",
      "    return r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Finding Parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Need to make sure the calls do not exceed the following: \n",
      "\n",
      "* 7200 requests a day, 300 per hour, 10 per minute and allow 5 seconds for your search to return results.\n",
      "\n",
      "To be safe there will be a 15 second wait between each call:\n",
      "\n",
      "* 15 sec per call\n",
      "* 4 calls per minute\n",
      "* 240 calls per hour"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Call for all articles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = plos_search(q='subject:\"Information technology\"')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check the total number of articles with abstracts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tot_articles = r.json()['response']['numFound']\n",
      "tot_articles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "1127"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With 118545 acticles total that means that we will have to perform 1,186 API requests at 100 articles per request.\n",
      "**At 240 requests per hour it should take about 5 hours to get all the data needed.**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Looping Function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function will call the plos_search function every 15 seconds while incrementing the start number so that all of the articles can be pulled."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@retry(wait='exponential_sleep', wait_exponential_multiplier=1000, wait_exponential_max=10000, stop='stop_after_attempt', stop_max_attempt_number=7)\n",
      "def data_request(end, start=0):\n",
      "    if os.path.exists('../data/abstract_df.pkl'):\n",
      "        df = pd.read_pickle('../data/abstract_df.pkl')\n",
      "        start = len(df)\n",
      "    current_end = end - start\n",
      "    loops = (current_end/100) + 1\n",
      "    for n in range(loops):\n",
      "        r = plos_search(q='subject:\"Information technology\"', start=start)\n",
      "        \n",
      "        #store data before next call\n",
      "        data = r.json()['response']['docs']\n",
      "        if start == 0:\n",
      "            abstract_df = pd.DataFrame(data)\n",
      "        else:\n",
      "            df = pd.read_pickle('../data/abstract_df.pkl')\n",
      "            abstract_df = df.append(pd.DataFrame(data))\n",
      "        \n",
      "        #increment the start for the next request\n",
      "        start+=100\n",
      "        \n",
      "        #every request pickle the dataframe\n",
      "        abstract_df.to_pickle('../data/abstract_df.pkl')\n",
      "        \n",
      "        #wait 15 seconds before the next loop\n",
      "        time.sleep(15)\n",
      "        \n",
      "    #pickle when finished\n",
      "    abstract_df.to_pickle('../data/abstract_df.pkl')\n",
      "    \n",
      "    return abstract_df\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Testing retry decorator\n",
      "\n",
      "This is making sure that the retry decorator works"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@retry\n",
      "def do_something_unreliable():\n",
      "    if random.randint(0, 2) > 1:\n",
      "        raise IOError(\"Broken sauce, everything is hosed!!!111one\")\n",
      "    else:\n",
      "        return \"Awesome sauce!\"\n",
      "\n",
      "print do_something_unreliable()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Awesome sauce!\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Making the call!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can run the function inputing the tot_articles as the end parameter.\n",
      "\n",
      "**Make sure that the 'abstract_df.pkl' does not exist in the `data` directory before running**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#abstract_df = data_request(end=tot_articles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exploring Output"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abstract_df = pd.read_pickle('../data/abstract_df.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(list(abstract_df.author))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "1120"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print list(abstract_df.subject)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'/Computer and information sciences/Information technology/Data processing', u'/Computer and information sciences/Information technology/Data reduction', u'/Physical sciences/Mathematics/Statistics (mathematics)/Statistical methods', u'/Research and analysis methods/Mathematical and statistical techniques/Statistical methods', u'/Computer and information sciences/Information technology/Databases', u'/Physical sciences/Mathematics/Statistics (mathematics)/Statistical data', u'/Computer and information sciences/Computer architecture/User interfaces', u'/Medicine and health sciences/Infectious diseases/Infectious disease control', u'/Computer and information sciences/Data management']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abstract_df.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>author</th>\n",
        "      <th>id</th>\n",
        "      <th>journal</th>\n",
        "      <th>publication_date</th>\n",
        "      <th>score</th>\n",
        "      <th>subject</th>\n",
        "      <th>title_display</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> [\\nPopulation structure can confound the ident...</td>\n",
        "      <td> [Jonathan Carlson, Carl Kadie, Simon Mallal, D...</td>\n",
        "      <td> 10.1371/journal.pone.0000591</td>\n",
        "      <td>                   PLoS ONE</td>\n",
        "      <td> 2007-07-04T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Biology and life sciences/Genetics/Phenotype...</td>\n",
        "      <td> Leveraging Hierarchical Population Structure i...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> [\\n        The discrimination of thatcherized ...</td>\n",
        "      <td> [Nick Donnelly, Nicole R Z\u00fcrcher, Katherine Co...</td>\n",
        "      <td> 10.1371/journal.pone.0023340</td>\n",
        "      <td>                   PLoS ONE</td>\n",
        "      <td> 2011-08-31T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Medicine and health sciences/Diagnostic medi...</td>\n",
        "      <td> Discriminating Grotesque from Typical Faces: E...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> [\\nInfluenza viruses have been responsible for...</td>\n",
        "      <td>           [Zhipeng Cai, Tong Zhang, Xiu-Feng Wan]</td>\n",
        "      <td> 10.1371/journal.pcbi.1000949</td>\n",
        "      <td> PLoS Computational Biology</td>\n",
        "      <td> 2010-10-07T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Biology and life sciences/Organisms/Viruses/...</td>\n",
        "      <td> A Computational Framework for Influenza Antige...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td> [\\n        Based on previous evidence for indi...</td>\n",
        "      <td> [Luis F H Basile, Jo\u00e3o R Sato, Milkes Y Alvare...</td>\n",
        "      <td> 10.1371/journal.pone.0059595</td>\n",
        "      <td>                   PLoS ONE</td>\n",
        "      <td> 2013-03-27T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Medicine and health sciences/Diagnostic medi...</td>\n",
        "      <td> Lack of Systematic Topographic Difference betw...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> [Objective: Herpes simplex virus type 2 (HSV-2...</td>\n",
        "      <td> [Alison C Roxby, Alison L Drake, Francisca Ong...</td>\n",
        "      <td> 10.1371/journal.pone.0038622</td>\n",
        "      <td>                   PLoS ONE</td>\n",
        "      <td> 2012-06-12T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Medicine and health sciences/Women's health/...</td>\n",
        "      <td> Effects of Valacyclovir on Markers of Disease ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 8 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "                                             abstract  \\\n",
        "15  [\\nPopulation structure can confound the ident...   \n",
        "16  [\\n        The discrimination of thatcherized ...   \n",
        "17  [\\nInfluenza viruses have been responsible for...   \n",
        "18  [\\n        Based on previous evidence for indi...   \n",
        "19  [Objective: Herpes simplex virus type 2 (HSV-2...   \n",
        "\n",
        "                                               author  \\\n",
        "15  [Jonathan Carlson, Carl Kadie, Simon Mallal, D...   \n",
        "16  [Nick Donnelly, Nicole R Z\u00fcrcher, Katherine Co...   \n",
        "17            [Zhipeng Cai, Tong Zhang, Xiu-Feng Wan]   \n",
        "18  [Luis F H Basile, Jo\u00e3o R Sato, Milkes Y Alvare...   \n",
        "19  [Alison C Roxby, Alison L Drake, Francisca Ong...   \n",
        "\n",
        "                              id                     journal  \\\n",
        "15  10.1371/journal.pone.0000591                    PLoS ONE   \n",
        "16  10.1371/journal.pone.0023340                    PLoS ONE   \n",
        "17  10.1371/journal.pcbi.1000949  PLoS Computational Biology   \n",
        "18  10.1371/journal.pone.0059595                    PLoS ONE   \n",
        "19  10.1371/journal.pone.0038622                    PLoS ONE   \n",
        "\n",
        "        publication_date     score  \\\n",
        "15  2007-07-04T00:00:00Z  0.443733   \n",
        "16  2011-08-31T00:00:00Z  0.443733   \n",
        "17  2010-10-07T00:00:00Z  0.443733   \n",
        "18  2013-03-27T00:00:00Z  0.443733   \n",
        "19  2012-06-12T00:00:00Z  0.443733   \n",
        "\n",
        "                                              subject  \\\n",
        "15  [/Biology and life sciences/Genetics/Phenotype...   \n",
        "16  [/Medicine and health sciences/Diagnostic medi...   \n",
        "17  [/Biology and life sciences/Organisms/Viruses/...   \n",
        "18  [/Medicine and health sciences/Diagnostic medi...   \n",
        "19  [/Medicine and health sciences/Women's health/...   \n",
        "\n",
        "                                        title_display  \n",
        "15  Leveraging Hierarchical Population Structure i...  \n",
        "16  Discriminating Grotesque from Typical Faces: E...  \n",
        "17  A Computational Framework for Influenza Antige...  \n",
        "18  Lack of Systematic Topographic Difference betw...  \n",
        "19  Effects of Valacyclovir on Markers of Disease ...  \n",
        "\n",
        "[5 rows x 8 columns]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Initial attempts to make word clouds using abstracts"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We wanted to use basic natural language processing (NLP) to make word clouds out of aggregated abstract text, and see how they change over time.\n",
      "\n",
      "NB: These examples use a previously collected dataset that's different and smaller than the one we generated above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Globally define a set of stopwords.\n",
      "stops = set(stopwords.words('english'))\n",
      "# We can add science-y stuff to it as well. Just an example:\n",
      "stops.add('conclusions')\n",
      "\n",
      "\n",
      "def wordify(abs_list, min_word_len=2):\n",
      "    '''\n",
      "    Convert the abstract field from PLoS API data to a filtered list of words.\n",
      "    '''\n",
      "\n",
      "    # The abstract field is a list. Make it a string.\n",
      "    text = ' '.join(abs_list).strip(' \\n\\t')\n",
      "\n",
      "    if text == '':\n",
      "        return nan\n",
      "\n",
      "    else:\n",
      "        # Remove punctuation & replace with space,\n",
      "        # because we want 'metal-contaminated' => 'metal contaminated'\n",
      "        # ...not 'metalcontaminated', and so on.\n",
      "        for c in string.punctuation:\n",
      "            text = text.replace(c, ' ')\n",
      "\n",
      "        # Now make it a Series of words, and do some cleaning.\n",
      "        words = Series(text.split(' '))\n",
      "        words = words.str.lower()\n",
      "        # Filter out words less than minimum word length.\n",
      "        words = words[words.str.len() >= min_word_len]\n",
      "        words = words[~words.str.contains(r'[^#@a-z]')]  # What exactly does this do?\n",
      "\n",
      "        # Filter out globally-defined stopwords\n",
      "        ignore = stops & set(words.unique())\n",
      "        words_out = [w for w in words.tolist() if w not in ignore]\n",
      "\n",
      "        return words_out\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load up some data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('biotech500.json', 'rb') as fp:\n",
      "    data = json.load(fp)\n",
      "    \n",
      "articles_list = data['response']['docs']\n",
      "articles = DataFrame(articles_list)\n",
      "articles = articles[articles['abstract'].notnull()]\n",
      "articles.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>article_type</th>\n",
        "      <th>author_display</th>\n",
        "      <th>eissn</th>\n",
        "      <th>id</th>\n",
        "      <th>journal</th>\n",
        "      <th>publication_date</th>\n",
        "      <th>score</th>\n",
        "      <th>title_display</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> [\\nThe objective of this paper is to assess th...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Latifah Amin, Md. Abul Kalam Azad, Mohd Hanaf...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0086174</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2014-01-29T00:00:00Z</td>\n",
        "      <td> 1.211935</td>\n",
        "      <td> Determinants of Public Attitudes to Geneticall...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> [\\n        Atrazine (ATZ) and S-metolachlor (S...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Cristina A. Viegas, Catarina Costa, Sandra An...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0037140</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2012-05-15T00:00:00Z</td>\n",
        "      <td> 1.119538</td>\n",
        "      <td> Does &lt;i&gt;S&lt;/i&gt;-Metolachlor Affect the Performan...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> [\\nDue to environmental persistence and biotox...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Yonggang Yang, Meiying Xu, Zhili He, Jun Guo,...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0070686</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2013-08-05T00:00:00Z</td>\n",
        "      <td> 1.119538</td>\n",
        "      <td> Microbial Electricity Generation Enhances Deca...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td> [\\n        Intensive use of chlorpyrifos has r...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Shaohua Chen, Chenglan Liu, Chuyan Peng, Hong...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0047205</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 2012-10-08T00:00:00Z</td>\n",
        "      <td> 1.119538</td>\n",
        "      <td> Biodegradation of Chlorpyrifos and Its Hydroly...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td> [Background: The complex characteristics and u...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Zhongbo Zhou, Fangang Meng, So-Ryong Chae, Gu...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0042270</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 2012-08-09T00:00:00Z</td>\n",
        "      <td> 0.989541</td>\n",
        "      <td> Microbial Transformation of Biomacromolecules ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 9 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "                                             abstract      article_type  \\\n",
        "7   [\\nThe objective of this paper is to assess th...  Research Article   \n",
        "16  [\\n        Atrazine (ATZ) and S-metolachlor (S...  Research Article   \n",
        "17  [\\nDue to environmental persistence and biotox...  Research Article   \n",
        "34  [\\n        Intensive use of chlorpyrifos has r...  Research Article   \n",
        "35  [Background: The complex characteristics and u...  Research Article   \n",
        "\n",
        "                                       author_display      eissn  \\\n",
        "7   [Latifah Amin, Md. Abul Kalam Azad, Mohd Hanaf...  1932-6203   \n",
        "16  [Cristina A. Viegas, Catarina Costa, Sandra An...  1932-6203   \n",
        "17  [Yonggang Yang, Meiying Xu, Zhili He, Jun Guo,...  1932-6203   \n",
        "34  [Shaohua Chen, Chenglan Liu, Chuyan Peng, Hong...  1932-6203   \n",
        "35  [Zhongbo Zhou, Fangang Meng, So-Ryong Chae, Gu...  1932-6203   \n",
        "\n",
        "                              id   journal      publication_date     score  \\\n",
        "7   10.1371/journal.pone.0086174  PLoS ONE  2014-01-29T00:00:00Z  1.211935   \n",
        "16  10.1371/journal.pone.0037140  PLoS ONE  2012-05-15T00:00:00Z  1.119538   \n",
        "17  10.1371/journal.pone.0070686  PLoS ONE  2013-08-05T00:00:00Z  1.119538   \n",
        "34  10.1371/journal.pone.0047205       NaN  2012-10-08T00:00:00Z  1.119538   \n",
        "35  10.1371/journal.pone.0042270       NaN  2012-08-09T00:00:00Z  0.989541   \n",
        "\n",
        "                                        title_display  \n",
        "7   Determinants of Public Attitudes to Geneticall...  \n",
        "16  Does <i>S</i>-Metolachlor Affect the Performan...  \n",
        "17  Microbial Electricity Generation Enhances Deca...  \n",
        "34  Biodegradation of Chlorpyrifos and Its Hydroly...  \n",
        "35  Microbial Transformation of Biomacromolecules ...  \n",
        "\n",
        "[5 rows x 9 columns]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Applying this to the whole DataFrame of articles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles['words'] = articles.apply(lambda s: wordify(s['abstract'] + [s['title_display']]), axis=1)\n",
      "articles.drop(['article_type', 'score', 'title_display', 'abstract'], axis=1, inplace=True)\n",
      "articles.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>author_display</th>\n",
        "      <th>eissn</th>\n",
        "      <th>id</th>\n",
        "      <th>journal</th>\n",
        "      <th>publication_date</th>\n",
        "      <th>words</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> [Latifah Amin, Md. Abul Kalam Azad, Mohd Hanaf...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0086174</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2014-01-29T00:00:00Z</td>\n",
        "      <td> [objective, paper, assess, attitude, malaysian...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> [Cristina A. Viegas, Catarina Costa, Sandra An...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0037140</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2012-05-15T00:00:00Z</td>\n",
        "      <td> [atrazine, atz, metolachlor, met, two, herbici...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> [Yonggang Yang, Meiying Xu, Zhili He, Jun Guo,...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0070686</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2013-08-05T00:00:00Z</td>\n",
        "      <td> [due, environmental, persistence, biotoxicity,...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td> [Shaohua Chen, Chenglan Liu, Chuyan Peng, Hong...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0047205</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 2012-10-08T00:00:00Z</td>\n",
        "      <td> [intensive, use, chlorpyrifos, resulted, ubiqu...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td> [Zhongbo Zhou, Fangang Meng, So-Ryong Chae, Gu...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0042270</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 2012-08-09T00:00:00Z</td>\n",
        "      <td> [background, complex, characteristics, unclear...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 6 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "                                       author_display      eissn  \\\n",
        "7   [Latifah Amin, Md. Abul Kalam Azad, Mohd Hanaf...  1932-6203   \n",
        "16  [Cristina A. Viegas, Catarina Costa, Sandra An...  1932-6203   \n",
        "17  [Yonggang Yang, Meiying Xu, Zhili He, Jun Guo,...  1932-6203   \n",
        "34  [Shaohua Chen, Chenglan Liu, Chuyan Peng, Hong...  1932-6203   \n",
        "35  [Zhongbo Zhou, Fangang Meng, So-Ryong Chae, Gu...  1932-6203   \n",
        "\n",
        "                              id   journal      publication_date  \\\n",
        "7   10.1371/journal.pone.0086174  PLoS ONE  2014-01-29T00:00:00Z   \n",
        "16  10.1371/journal.pone.0037140  PLoS ONE  2012-05-15T00:00:00Z   \n",
        "17  10.1371/journal.pone.0070686  PLoS ONE  2013-08-05T00:00:00Z   \n",
        "34  10.1371/journal.pone.0047205       NaN  2012-10-08T00:00:00Z   \n",
        "35  10.1371/journal.pone.0042270       NaN  2012-08-09T00:00:00Z   \n",
        "\n",
        "                                                words  \n",
        "7   [objective, paper, assess, attitude, malaysian...  \n",
        "16  [atrazine, atz, metolachlor, met, two, herbici...  \n",
        "17  [due, environmental, persistence, biotoxicity,...  \n",
        "34  [intensive, use, chlorpyrifos, resulted, ubiqu...  \n",
        "35  [background, complex, characteristics, unclear...  \n",
        "\n",
        "[5 rows x 6 columns]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Doing some natural language processing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abs_df = DataFrame(articles['words'].apply(lambda x: ' '.join(x)).tolist(), columns=['text'])\n",
      "abs_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> objective paper assess attitude malaysian stak...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> atrazine atz metolachlor met two herbicides wi...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> due environmental persistence biotoxicity poly...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> intensive use chlorpyrifos resulted ubiquitous...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> background complex characteristics unclear bio...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "                                                text\n",
        "0  objective paper assess attitude malaysian stak...\n",
        "1  atrazine atz metolachlor met two herbicides wi...\n",
        "2  due environmental persistence biotoxicity poly...\n",
        "3  intensive use chlorpyrifos resulted ubiquitous...\n",
        "4  background complex characteristics unclear bio...\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Common word pairs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section uses all words from abstracts to find the common word pairs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#include all words from abstracts for getting common word pairs\n",
      "words_all = pd.Series(' '.join(abs_df['text']).split(' '))\n",
      "words_all.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "study             56\n",
        "using             33\n",
        "two               32\n",
        "patients          31\n",
        "biodegradation    30\n",
        "non               29\n",
        "data              28\n",
        "three             28\n",
        "analysis          27\n",
        "compared          27\n",
        "soil              27\n",
        "new               27\n",
        "results           26\n",
        "species           25\n",
        "cell              25\n",
        "...\n",
        "engage             1\n",
        "thermal            1\n",
        "geochip            1\n",
        "dominant           1\n",
        "suggests           1\n",
        "third              1\n",
        "usually            1\n",
        "locomotion         1\n",
        "rpos               1\n",
        "scales             1\n",
        "prefer             1\n",
        "quite              1\n",
        "protocatechuate    1\n",
        "routine            1\n",
        "agr                1\n",
        "Length: 3028, dtype: int64"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "relevant_words_pairs = words_all.copy()\n",
      "relevant_words_pairs.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "study             56\n",
        "using             33\n",
        "two               32\n",
        "patients          31\n",
        "biodegradation    30\n",
        "non               29\n",
        "data              28\n",
        "three             28\n",
        "analysis          27\n",
        "compared          27\n",
        "soil              27\n",
        "new               27\n",
        "results           26\n",
        "species           25\n",
        "cell              25\n",
        "...\n",
        "engage             1\n",
        "thermal            1\n",
        "geochip            1\n",
        "dominant           1\n",
        "suggests           1\n",
        "third              1\n",
        "usually            1\n",
        "locomotion         1\n",
        "rpos               1\n",
        "scales             1\n",
        "prefer             1\n",
        "quite              1\n",
        "protocatechuate    1\n",
        "routine            1\n",
        "agr                1\n",
        "Length: 3028, dtype: int64"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bcf = BigramCollocationFinder.from_words(relevant_words_pairs)\n",
      "for pair in bcf.nbest(BigramAssocMeasures.likelihood_ratio, 30):\n",
      "    print ' '.join(pair)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synthetic biology\n",
        "spider silk\n",
        "es cell\n",
        "adjacent segment\n",
        "medical imaging\n",
        "dp dtmax\n",
        "security privacy\n",
        "industry backgrounds\n",
        "removal initiation\n",
        "uv irradiated\n",
        "gm salmon\n",
        "persistent crsab\n",
        "antimicrobial therapy\n",
        "limb amputation\n",
        "cellular phone\n",
        "wireless powered\n",
        "minimally invasive\n",
        "phone technology\n",
        "heavy metals\n",
        "battery powered\n",
        "composite mesh\n",
        "frequency currents\n",
        "genetically modified\n",
        "tissue engineering\n",
        "catheter removal\n",
        "acting reversible\n",
        "brassica napus\n",
        "brown streak\n",
        "quasi stiffness\n",
        "data code\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bcf.nbest(BigramAssocMeasures.likelihood_ratio, 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[(u'synthetic', u'biology'),\n",
        " (u'spider', u'silk'),\n",
        " (u'es', u'cell'),\n",
        " (u'adjacent', u'segment'),\n",
        " (u'medical', u'imaging'),\n",
        " (u'dp', u'dtmax'),\n",
        " (u'security', u'privacy'),\n",
        " (u'industry', u'backgrounds'),\n",
        " (u'removal', u'initiation'),\n",
        " (u'uv', u'irradiated'),\n",
        " (u'gm', u'salmon'),\n",
        " (u'persistent', u'crsab'),\n",
        " (u'antimicrobial', u'therapy'),\n",
        " (u'limb', u'amputation'),\n",
        " (u'cellular', u'phone'),\n",
        " (u'wireless', u'powered'),\n",
        " (u'minimally', u'invasive'),\n",
        " (u'phone', u'technology'),\n",
        " (u'heavy', u'metals'),\n",
        " (u'battery', u'powered')]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Making word clouds: select the top words"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we takes only unique words from each abstract."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abs_set_df = DataFrame(articles['words'].apply(lambda x: ' '.join(set(x))).tolist(), columns=['text'])\n",
      "abs_set_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> among developed attitude paper identify accept...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> aquatic mineralization dose experiments still ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> mfc hypothesized distinctly results nitrogen s...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> fungal contaminant tcp accumulative gc morphol...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> origin humic mineralization show mainly result...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "                                                text\n",
        "0  among developed attitude paper identify accept...\n",
        "1  aquatic mineralization dose experiments still ...\n",
        "2  mfc hypothesized distinctly results nitrogen s...\n",
        "3  fungal contaminant tcp accumulative gc morphol...\n",
        "4  origin humic mineralization show mainly result...\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = pd.Series(' '.join(abs_set_df['text']).split(' '))\n",
      "words.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "study            38\n",
        "two              23\n",
        "using            21\n",
        "results          20\n",
        "three            20\n",
        "analysis         20\n",
        "compared         17\n",
        "used             16\n",
        "higher           16\n",
        "may              16\n",
        "non              15\n",
        "based            15\n",
        "significantly    14\n",
        "also             14\n",
        "however          14\n",
        "...\n",
        "septal             1\n",
        "recommendations    1\n",
        "genomes            1\n",
        "poking             1\n",
        "gck                1\n",
        "optimised          1\n",
        "varied             1\n",
        "counting           1\n",
        "monitoring         1\n",
        "malware            1\n",
        "tmc                1\n",
        "rape               1\n",
        "occur              1\n",
        "conversely         1\n",
        "cda                1\n",
        "Length: 3028, dtype: int64"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_words = words.value_counts().reset_index()\n",
      "top_words.columns = ['word', 'count']\n",
      "top_words.head(15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>word</th>\n",
        "      <th>count</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>         study</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>           two</td>\n",
        "      <td> 23</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>         using</td>\n",
        "      <td> 21</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>       results</td>\n",
        "      <td> 20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>         three</td>\n",
        "      <td> 20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>      analysis</td>\n",
        "      <td> 20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>      compared</td>\n",
        "      <td> 17</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>          used</td>\n",
        "      <td> 16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>        higher</td>\n",
        "      <td> 16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>           may</td>\n",
        "      <td> 16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>           non</td>\n",
        "      <td> 15</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>         based</td>\n",
        "      <td> 15</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> significantly</td>\n",
        "      <td> 14</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>          also</td>\n",
        "      <td> 14</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>       however</td>\n",
        "      <td> 14</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>15 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "             word  count\n",
        "0           study     38\n",
        "1             two     23\n",
        "2           using     21\n",
        "3         results     20\n",
        "4           three     20\n",
        "5        analysis     20\n",
        "6        compared     17\n",
        "7            used     16\n",
        "8          higher     16\n",
        "9             may     16\n",
        "10            non     15\n",
        "11          based     15\n",
        "12  significantly     14\n",
        "13           also     14\n",
        "14        however     14\n",
        "\n",
        "[15 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Exporting word count data as CSV for D3 word-cloudification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# top_words.to_csv('../wordcloud2.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Initial word cloud results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When we created the word clouds, we noticed something about the most common words in these article abstracts... \n",
      "\n",
      "![cloud](../wordcloud_example_old.jpg)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Change over time: working with article abstracts as time series data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_list = data['response']['docs']\n",
      "articles = DataFrame(articles_list)\n",
      "articles = articles[articles['abstract'].notnull()].ix[:,['abstract', 'publication_date']]\n",
      "articles.abstract = articles.abstract.apply(wordify, 3)\n",
      "articles = articles[articles['abstract'].notnull()]\n",
      "articles.publication_date = pd.to_datetime(articles.publication_date)\n",
      "articles.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>publication_date</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> [objective, paper, assess, attitude, malaysian...</td>\n",
        "      <td>2014-01-29</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> [atrazine, atz, metolachlor, met, two, herbici...</td>\n",
        "      <td>2012-05-15</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> [due, environmental, persistence, biotoxicity,...</td>\n",
        "      <td>2013-08-05</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td> [intensive, use, chlorpyrifos, resulted, ubiqu...</td>\n",
        "      <td>2012-10-08</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td> [background, complex, characteristics, unclear...</td>\n",
        "      <td>2012-08-09</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "                                             abstract publication_date\n",
        "7   [objective, paper, assess, attitude, malaysian...       2014-01-29\n",
        "16  [atrazine, atz, metolachlor, met, two, herbici...       2012-05-15\n",
        "17  [due, environmental, persistence, biotoxicity,...       2013-08-05\n",
        "34  [intensive, use, chlorpyrifos, resulted, ubiqu...       2012-10-08\n",
        "35  [background, complex, characteristics, unclear...       2012-08-09\n",
        "\n",
        "[5 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print articles.publication_date.min(), articles.publication_date.max()\n",
      "print len(articles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2008-04-30 00:00:00 2014-04-11 00:00:00\n",
        "57\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The time series spans ~9 years with 57 data points. **We need to resample!**\n",
      "\n",
      "There are probably many ways to do this..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_timed = articles.set_index('publication_date')\n",
      "articles_timed.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>publication_date</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2014-01-29</th>\n",
        "      <td> [objective, paper, assess, attitude, malaysian...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2012-05-15</th>\n",
        "      <td> [atrazine, atz, metolachlor, met, two, herbici...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013-08-05</th>\n",
        "      <td> [due, environmental, persistence, biotoxicity,...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2012-10-08</th>\n",
        "      <td> [intensive, use, chlorpyrifos, resulted, ubiqu...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2012-08-09</th>\n",
        "      <td> [background, complex, characteristics, unclear...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "                                                           abstract\n",
        "publication_date                                                   \n",
        "2014-01-29        [objective, paper, assess, attitude, malaysian...\n",
        "2012-05-15        [atrazine, atz, metolachlor, met, two, herbici...\n",
        "2013-08-05        [due, environmental, persistence, biotoxicity,...\n",
        "2012-10-08        [intensive, use, chlorpyrifos, resulted, ubiqu...\n",
        "2012-08-09        [background, complex, characteristics, unclear...\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Using pandas time series resampling functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the `sum` aggregation method works because all the values were lists. The three abstracts published in 2013-05 were concatenated together (see below)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_monthly = articles_timed.resample('M', how='sum', fill_method='ffill', kind='period')\n",
      "articles_monthly.abstract = articles_monthly.abstract.apply(lambda x: np.nan if x == 0 else x)\n",
      "articles_monthly.fillna(method='ffill', inplace=True)\n",
      "articles_monthly.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>publication_date</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2008-04</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008-05</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008-06</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008-07</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008-08</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "                                                           abstract\n",
        "publication_date                                                   \n",
        "2008-04           [according, world, health, organization, repor...\n",
        "2008-05           [according, world, health, organization, repor...\n",
        "2008-06           [according, world, health, organization, repor...\n",
        "2008-07           [according, world, health, organization, repor...\n",
        "2008-08           [according, world, health, organization, repor...\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Making a time slider for abstract text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "widgetmax = len(articles_monthly) - 1\n",
      "\n",
      "def textbarf(t): \n",
      "    html_template = \"\"\"\n",
      "    <style>\n",
      "    #textbarf {\n",
      "        display: block;\n",
      "        width: 666px;\n",
      "        padding: 23px;\n",
      "        background-color: #ddeeff;\n",
      "    }\n",
      "    </style>\n",
      "    <div id=\"textbarf\"> {{blargh}} </div>\"\"\"\n",
      "\n",
      "    blob = ' '.join(articles_monthly.ix[t]['abstract'])\n",
      "    html_src = Template(html_template).render(blargh=blob)\n",
      "    display(HTML(html_src))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "widgets.interact(textbarf,\n",
      "                 t=widgets.IntSliderWidget(min=0,max=widgetmax,step=1,value=42),\n",
      "                )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "    <style>\n",
        "    #textbarf {\n",
        "        display: block;\n",
        "        width: 666px;\n",
        "        padding: 23px;\n",
        "        background-color: #ddeeff;\n",
        "    }\n",
        "    </style>\n",
        "    <div id=\"textbarf\"> concerns regarding commercial release genetically engineered ge crops include naturalization introgression sexually compatible relatives transfer beneficial traits native weedy species hybridization date documented reports escape leading researchers question environmental risks biotech products study conducted systematic roadside survey canola brassica napus populations growing outside cultivation north dakota usa dominant canola growing region document presence two escaped transgenic genotypes well non ge canola provide evidence novel combinations transgenic forms wild results demonstrate feral populations large widespread moreover flowering times escaped populations well fertile condition majority collections suggest populations established persistent outside cultivation </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x1099400d0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "<function __main__.textbarf>"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Transforming batch-collected article data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The desired data structure for article information is the following JSON object:\n",
      "\n",
      "```\n",
      "<doi1>: {\n",
      "    author: [ ... ]\n",
      "    title:\n",
      "    journal:\n",
      "    publication_date: <yyyy>\n",
      "    subject: [ <full subject /-separated strings>, ... ]\n",
      "    subj_top: [ set of top levels of each subject ]\n",
      "    subj_leaf: [ set of last terms of each subject ]\n",
      "},\n",
      "<doi2>: { ... }, \n",
      "...\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_pickle('../data/abstract_df.pkl')\n",
      "\n",
      "# Dropping abstract and score.\n",
      "df.drop(['abstract', 'score'], axis=1, inplace=True)\n",
      "df.set_index('id', inplace=True)\n",
      "df.columns = ['author', 'journal', 'publication_date', 'subject', 'title']\n",
      "df = df.reindex(columns=['author', 'title', 'journal', 'publication_date', 'subject'])\n",
      "# We just want the year.\n",
      "df.publication_date = df.publication_date.str[:4]\n",
      "\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>author</th>\n",
        "      <th>title</th>\n",
        "      <th>journal</th>\n",
        "      <th>publication_date</th>\n",
        "      <th>subject</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>id</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>10.1371/journal.pntd.0000413</th>\n",
        "      <td> [Darren J Gray, Simon J Forsyth, Robert S Li, ...</td>\n",
        "      <td> An Innovative Database for Epidemiological Fie...</td>\n",
        "      <td> PLoS Neglected Tropical Diseases</td>\n",
        "      <td> 2009</td>\n",
        "      <td> [/Computer and information sciences/Informatio...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10.1371/journal.pone.0083016</th>\n",
        "      <td> [Pedro Lopes, Tiago Nunes, David Campos, Laura...</td>\n",
        "      <td> Gathering and Exploring Scientific Knowledge i...</td>\n",
        "      <td>                         PLoS ONE</td>\n",
        "      <td> 2013</td>\n",
        "      <td> [/Medicine and health sciences/Pharmacology/Dr...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10.1371/journal.pmed.0030249</th>\n",
        "      <td>                               [Matthew E Falagas]</td>\n",
        "      <td> Unique Author Identification Number in Scienti...</td>\n",
        "      <td>                    PLoS Medicine</td>\n",
        "      <td> 2006</td>\n",
        "      <td> [/Research and analysis methods/Database and i...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10.1371/journal.pone.0073275</th>\n",
        "      <td>                               [George J Besseris]</td>\n",
        "      <td> A Distribution-Free Multi-Factorial Profiler f...</td>\n",
        "      <td>                         PLoS ONE</td>\n",
        "      <td> 2013</td>\n",
        "      <td> [/Computer and information sciences/Informatio...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10.1371/journal.pone.0043558</th>\n",
        "      <td> [Yuncui Hu, Yanpeng Li, Hongfei Lin, Zhihao Ya...</td>\n",
        "      <td> Integrating Various Resources for Gene Name No...</td>\n",
        "      <td>                              NaN</td>\n",
        "      <td> 2012</td>\n",
        "      <td> [/Computer and information sciences/Informatio...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 5 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "                                                                         author  \\\n",
        "id                                                                                \n",
        "10.1371/journal.pntd.0000413  [Darren J Gray, Simon J Forsyth, Robert S Li, ...   \n",
        "10.1371/journal.pone.0083016  [Pedro Lopes, Tiago Nunes, David Campos, Laura...   \n",
        "10.1371/journal.pmed.0030249                                [Matthew E Falagas]   \n",
        "10.1371/journal.pone.0073275                                [George J Besseris]   \n",
        "10.1371/journal.pone.0043558  [Yuncui Hu, Yanpeng Li, Hongfei Lin, Zhihao Ya...   \n",
        "\n",
        "                                                                          title  \\\n",
        "id                                                                                \n",
        "10.1371/journal.pntd.0000413  An Innovative Database for Epidemiological Fie...   \n",
        "10.1371/journal.pone.0083016  Gathering and Exploring Scientific Knowledge i...   \n",
        "10.1371/journal.pmed.0030249  Unique Author Identification Number in Scienti...   \n",
        "10.1371/journal.pone.0073275  A Distribution-Free Multi-Factorial Profiler f...   \n",
        "10.1371/journal.pone.0043558  Integrating Various Resources for Gene Name No...   \n",
        "\n",
        "                                                       journal  \\\n",
        "id                                                               \n",
        "10.1371/journal.pntd.0000413  PLoS Neglected Tropical Diseases   \n",
        "10.1371/journal.pone.0083016                          PLoS ONE   \n",
        "10.1371/journal.pmed.0030249                     PLoS Medicine   \n",
        "10.1371/journal.pone.0073275                          PLoS ONE   \n",
        "10.1371/journal.pone.0043558                               NaN   \n",
        "\n",
        "                             publication_date  \\\n",
        "id                                              \n",
        "10.1371/journal.pntd.0000413             2009   \n",
        "10.1371/journal.pone.0083016             2013   \n",
        "10.1371/journal.pmed.0030249             2006   \n",
        "10.1371/journal.pone.0073275             2013   \n",
        "10.1371/journal.pone.0043558             2012   \n",
        "\n",
        "                                                                        subject  \n",
        "id                                                                               \n",
        "10.1371/journal.pntd.0000413  [/Computer and information sciences/Informatio...  \n",
        "10.1371/journal.pone.0083016  [/Medicine and health sciences/Pharmacology/Dr...  \n",
        "10.1371/journal.pmed.0030249  [/Research and analysis methods/Database and i...  \n",
        "10.1371/journal.pone.0073275  [/Computer and information sciences/Informatio...  \n",
        "10.1371/journal.pone.0043558  [/Computer and information sciences/Informatio...  \n",
        "\n",
        "[5 rows x 5 columns]"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_subj_top(subjects):\n",
      "    subj_top = set()\n",
      "    for s in subjects:\n",
      "        # the string gets split at its first character, so not [0] here:\n",
      "        subj_top.add(s.split('/')[1])\n",
      "    return subj_top\n",
      "\n",
      "def get_subj_leaf(subjects):\n",
      "    subj_top = set()\n",
      "    for s in subjects:\n",
      "        subj_top.add(s.split('/')[-1])\n",
      "    return subj_top"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['subj_top'] = df.subject.apply(get_subj_top)\n",
      "df['subj_leaf'] = df.subject.apply(get_subj_leaf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>author</th>\n",
        "      <th>title</th>\n",
        "      <th>journal</th>\n",
        "      <th>publication_date</th>\n",
        "      <th>subject</th>\n",
        "      <th>subj_top</th>\n",
        "      <th>subj_leaf</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>id</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>10.1371/journal.pntd.0000413</th>\n",
        "      <td> [Darren J Gray, Simon J Forsyth, Robert S Li, ...</td>\n",
        "      <td> An Innovative Database for Epidemiological Fie...</td>\n",
        "      <td> PLoS Neglected Tropical Diseases</td>\n",
        "      <td> 2009</td>\n",
        "      <td> [/Computer and information sciences/Informatio...</td>\n",
        "      <td> set([Physical sciences, Medicine and health sc...</td>\n",
        "      <td> set([Statistical methods, Infectious disease c...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10.1371/journal.pone.0083016</th>\n",
        "      <td> [Pedro Lopes, Tiago Nunes, David Campos, Laura...</td>\n",
        "      <td> Gathering and Exploring Scientific Knowledge i...</td>\n",
        "      <td>                         PLoS ONE</td>\n",
        "      <td> 2013</td>\n",
        "      <td> [/Medicine and health sciences/Pharmacology/Dr...</td>\n",
        "      <td> set([Medicine and health sciences, Engineering...</td>\n",
        "      <td> set([Signal processing, Engines, Drug interact...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10.1371/journal.pmed.0030249</th>\n",
        "      <td>                               [Matthew E Falagas]</td>\n",
        "      <td> Unique Author Identification Number in Scienti...</td>\n",
        "      <td>                    PLoS Medicine</td>\n",
        "      <td> 2006</td>\n",
        "      <td> [/Research and analysis methods/Database and i...</td>\n",
        "      <td> set([Engineering and technology, Research and ...</td>\n",
        "      <td> set([Database searching, Electronics, Data pro...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10.1371/journal.pone.0073275</th>\n",
        "      <td>                               [George J Besseris]</td>\n",
        "      <td> A Distribution-Free Multi-Factorial Profiler f...</td>\n",
        "      <td>                         PLoS ONE</td>\n",
        "      <td> 2013</td>\n",
        "      <td> [/Computer and information sciences/Informatio...</td>\n",
        "      <td> set([Biology and life sciences, Physical scien...</td>\n",
        "      <td> set([Statistical distributions, Engineering an...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10.1371/journal.pone.0043558</th>\n",
        "      <td> [Yuncui Hu, Yanpeng Li, Hongfei Lin, Zhihao Ya...</td>\n",
        "      <td> Integrating Various Resources for Gene Name No...</td>\n",
        "      <td>                              NaN</td>\n",
        "      <td> 2012</td>\n",
        "      <td> [/Computer and information sciences/Informatio...</td>\n",
        "      <td> set([Biology and life sciences, Physical scien...</td>\n",
        "      <td> set([Text mining, Gene mapping, Entity disambi...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 7 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "                                                                         author  \\\n",
        "id                                                                                \n",
        "10.1371/journal.pntd.0000413  [Darren J Gray, Simon J Forsyth, Robert S Li, ...   \n",
        "10.1371/journal.pone.0083016  [Pedro Lopes, Tiago Nunes, David Campos, Laura...   \n",
        "10.1371/journal.pmed.0030249                                [Matthew E Falagas]   \n",
        "10.1371/journal.pone.0073275                                [George J Besseris]   \n",
        "10.1371/journal.pone.0043558  [Yuncui Hu, Yanpeng Li, Hongfei Lin, Zhihao Ya...   \n",
        "\n",
        "                                                                          title  \\\n",
        "id                                                                                \n",
        "10.1371/journal.pntd.0000413  An Innovative Database for Epidemiological Fie...   \n",
        "10.1371/journal.pone.0083016  Gathering and Exploring Scientific Knowledge i...   \n",
        "10.1371/journal.pmed.0030249  Unique Author Identification Number in Scienti...   \n",
        "10.1371/journal.pone.0073275  A Distribution-Free Multi-Factorial Profiler f...   \n",
        "10.1371/journal.pone.0043558  Integrating Various Resources for Gene Name No...   \n",
        "\n",
        "                                                       journal  \\\n",
        "id                                                               \n",
        "10.1371/journal.pntd.0000413  PLoS Neglected Tropical Diseases   \n",
        "10.1371/journal.pone.0083016                          PLoS ONE   \n",
        "10.1371/journal.pmed.0030249                     PLoS Medicine   \n",
        "10.1371/journal.pone.0073275                          PLoS ONE   \n",
        "10.1371/journal.pone.0043558                               NaN   \n",
        "\n",
        "                             publication_date  \\\n",
        "id                                              \n",
        "10.1371/journal.pntd.0000413             2009   \n",
        "10.1371/journal.pone.0083016             2013   \n",
        "10.1371/journal.pmed.0030249             2006   \n",
        "10.1371/journal.pone.0073275             2013   \n",
        "10.1371/journal.pone.0043558             2012   \n",
        "\n",
        "                                                                        subject  \\\n",
        "id                                                                                \n",
        "10.1371/journal.pntd.0000413  [/Computer and information sciences/Informatio...   \n",
        "10.1371/journal.pone.0083016  [/Medicine and health sciences/Pharmacology/Dr...   \n",
        "10.1371/journal.pmed.0030249  [/Research and analysis methods/Database and i...   \n",
        "10.1371/journal.pone.0073275  [/Computer and information sciences/Informatio...   \n",
        "10.1371/journal.pone.0043558  [/Computer and information sciences/Informatio...   \n",
        "\n",
        "                                                                       subj_top  \\\n",
        "id                                                                                \n",
        "10.1371/journal.pntd.0000413  set([Physical sciences, Medicine and health sc...   \n",
        "10.1371/journal.pone.0083016  set([Medicine and health sciences, Engineering...   \n",
        "10.1371/journal.pmed.0030249  set([Engineering and technology, Research and ...   \n",
        "10.1371/journal.pone.0073275  set([Biology and life sciences, Physical scien...   \n",
        "10.1371/journal.pone.0043558  set([Biology and life sciences, Physical scien...   \n",
        "\n",
        "                                                                      subj_leaf  \n",
        "id                                                                               \n",
        "10.1371/journal.pntd.0000413  set([Statistical methods, Infectious disease c...  \n",
        "10.1371/journal.pone.0083016  set([Signal processing, Engines, Drug interact...  \n",
        "10.1371/journal.pmed.0030249  set([Database searching, Electronics, Data pro...  \n",
        "10.1371/journal.pone.0073275  set([Statistical distributions, Engineering an...  \n",
        "10.1371/journal.pone.0043558  set([Text mining, Gene mapping, Entity disambi...  \n",
        "\n",
        "[5 rows x 7 columns]"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "If all is OK, export.."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# df.to_json(path_or_buf='../data/articles.json', orient='index', force_ascii=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Transforming the PLOS thesaurus"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The PLOS thesaurus was kindly provided to us as a spreadsheet with thousands of rows, one node per row. It is a polyhierarchy represented in the form of a tree. We need to transform it into a JSON object that also includes article counts for all the nodes in the tree.\n",
      "\n",
      "An example of the desired data structure for PLOS thesaurus:\n",
      "\n",
      "```\n",
      "{ \n",
      "  \"name\": \"Computer and information sciences\",\n",
      "  \"count\": ###,\n",
      "  \"children\": [\n",
      "    {\n",
      "      \"name\": \"Information technology\",\n",
      "      \"count\": ###,\n",
      "      \"children\": [\n",
      "        {\"name\": \"Data mining\", \"count\": ###},\n",
      "        {\"name\": \"Data reduction\", \"count\": ###}, \n",
      "        {\n",
      "          \"name\":  \"Databases\",\n",
      "          \"count\": ###,\n",
      "          \"children\": [\n",
      "            {\"name\": \"Relational databases\", \"count\": ###}\n",
      "          ]\n",
      "        },\n",
      "        ...,\n",
      "        {\"name\": \"Text mining\",\"count\": ###} \n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}, \n",
      "...\n",
      "```\n",
      "\n",
      "In Python, each node is a dict. Children are specified as a list of dicts. The whole thing is a list of nodes, therefore, a list of dicts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's make sure we are counting articles correctly for each subject node.\n",
      "\n",
      "def count_articles(df, subject_path):\n",
      "    s = df.subject.apply(lambda s: str(s))\n",
      "    matching = s[s.str.contains(subject_path)]\n",
      "    return len(matching)\n",
      "\n",
      "print 'Total articles:', len(df)\n",
      "print 'Science policy:', count_articles(df, 'Science policy')\n",
      "print 'Science policy/Bioethics:', count_articles(df, 'Science policy/Bioethics')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total articles: 1120\n",
        "Science policy: 31\n",
        "Science policy/Bioethics: 2\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tree_from_spreadsheet(f, df, verbose=False):\n",
      "    \n",
      "    subjects = df.subject.apply(lambda s: str(s))\n",
      "    \n",
      "    book = xlrd.open_workbook(f)\n",
      "    pt = book.sheet_by_index(0)\n",
      "    # spreadsheet cells : (row, col) :: cell A1 = (0, 0)\n",
      "\n",
      "    # Initialize a list to contain the thesaurus.\n",
      "    # Our test case will only have one item in this list.\n",
      "    pt_test = []\n",
      "\n",
      "    # Keep track of the path in the tree.\n",
      "    cur_path = Series([np.nan]*10)\n",
      "\n",
      "    for r in range(1, pt.nrows):\n",
      "        # Start on row two.\n",
      "\n",
      "        # Columns: the hierarchy goes up to 10 tiers.\n",
      "        for c in range(10):\n",
      "            if pt.cell_value(r, c):\n",
      "                # If this condition is satisfied, we are at the node that's in this line.\n",
      "\n",
      "                # Construct the path to this node.\n",
      "                # Clean strings because some terms (RNA nomenclature) cause unicode error\n",
      "                text = pt.cell_value(r, c).replace(u'\\u2019', \"'\")\n",
      "                cur_path[c] = text\n",
      "                cur_path[c+1:] = np.nan\n",
      "                path_list = list(cur_path.dropna())\n",
      "                tier = len(path_list)\n",
      "                path_str = '/'.join(path_list)\n",
      "                if verbose:\n",
      "                    print tier, path_str\n",
      "\n",
      "                # Add the node to the JSON-like tree structure.\n",
      "                node = defaultdict(list)\n",
      "                node['name'] = text\n",
      "                node['count']=  len(subjects[subjects.str.contains(path_str)])\n",
      "\n",
      "                # This part is completely ridiculous. But it seems to work.\n",
      "                if tier == 1:\n",
      "                    pt_test.append(node)\n",
      "                    pt_test.append\n",
      "                elif tier == 2:\n",
      "                    pt_test[-1]['children'].append(node)\n",
      "                elif tier == 3:\n",
      "                    pt_test[-1]['children'][-1]['children'].append(node)\n",
      "                elif tier == 4:\n",
      "                    pt_test[-1]['children'][-1]['children'][-1]['children'].append(node)\n",
      "                elif tier == 5:\n",
      "                    pt_test[-1]['children'][-1]['children'][-1]['children'].append(node)\n",
      "                elif tier == 6:\n",
      "                    pt_test[-1]['children'][-1]['children'][-1]['children'][-1]['children'].append(node)\n",
      "                elif tier == 7:\n",
      "                    pt_test[-1]['children'][-1]['children'][-1]['children'][-1]['children'][-1]['children'].append(node)\n",
      "                elif tier == 8:\n",
      "                    pt_test[-1]['children'][-1]['children'][-1]['children'][-1]['children'][-1]['children'][-1]['children'].append(node)\n",
      "                elif tier == 9:\n",
      "                    pt_test[-1]['children'][-1]['children'][-1]['children'][-1]['children'][-1]['children'][-1]['children'][-1]['children'].append(node)\n",
      "                elif tier == 10:\n",
      "                    pt_test[-1]['children'][-1]['children'][-1]['children'][-1]['children'][-1]['children'][-1]['children'][-1]['children'][-1]['children'].append(node)\n",
      "\n",
      "                # Go to next row after finding a term. There is only one term listed per row.\n",
      "                break\n",
      "\n",
      "    return pt_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Experimenting on a small subset of the thesaurus"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have made an excerpt of the full spreadsheet, which contains only the very small ``Science policy`` branch."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plosthes_test_file = '../data/plosthes_test.xlsx'\n",
      "\n",
      "json.dumps(tree_from_spreadsheet(plosthes_test_file, df, verbose=True))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 Science policy\n",
        "2 Science policy/Bioethics\n",
        "3 Science policy/Bioethics/Justice in science\n",
        "3 Science policy/Bioethics/Respect for human dignity\n",
        "3 Science policy/Bioethics/Sanctity of life\n",
        "3 Science policy/Bioethics/Scientific beneficence\n",
        "3 Science policy/Bioethics/Scientific nonmaleficence\n",
        "2 Science policy/Material transfer agreements\n",
        "2 Science policy/Research funding\n",
        "3 Science policy/Research funding/Corporate funding of science\n",
        "3 Science policy/Research funding/Government funding of science\n",
        "3 Science policy/Research funding/Institutional funding of science\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Science policy/Research funding/Military funding of science\n",
        "3 Science policy/Research funding/Philanthropic funding of science\n",
        "3 Science policy/Research funding/Research grants\n",
        "2 Science policy/Research integrity\n",
        "3 Science policy/Research integrity/Publication ethics\n",
        "3 Science policy/Research integrity/Scientific misconduct\n",
        "2 Science policy/Science and technology workforce\n",
        "3 Science policy/Science and technology workforce/Careers in research\n",
        "2 Science policy/Science education\n",
        "3 Science policy/Science education/Science fairs\n",
        "2 Science policy/Science policy and economics\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Science policy/Technology regulations\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "'[{\"count\": 31, \"name\": \"Science policy\", \"children\": [{\"count\": 2, \"name\": \"Bioethics\", \"children\": [{\"count\": 0, \"name\": \"Justice in science\"}, {\"count\": 0, \"name\": \"Respect for human dignity\"}, {\"count\": 0, \"name\": \"Sanctity of life\"}, {\"count\": 0, \"name\": \"Scientific beneficence\"}, {\"count\": 0, \"name\": \"Scientific nonmaleficence\"}]}, {\"count\": 0, \"name\": \"Material transfer agreements\"}, {\"count\": 14, \"name\": \"Research funding\", \"children\": [{\"count\": 0, \"name\": \"Corporate funding of science\"}, {\"count\": 6, \"name\": \"Government funding of science\"}, {\"count\": 1, \"name\": \"Institutional funding of science\"}, {\"count\": 0, \"name\": \"Military funding of science\"}, {\"count\": 1, \"name\": \"Philanthropic funding of science\"}, {\"count\": 3, \"name\": \"Research grants\"}]}, {\"count\": 5, \"name\": \"Research integrity\", \"children\": [{\"count\": 3, \"name\": \"Publication ethics\"}, {\"count\": 0, \"name\": \"Scientific misconduct\"}]}, {\"count\": 0, \"name\": \"Science and technology workforce\", \"children\": [{\"count\": 0, \"name\": \"Careers in research\"}]}, {\"count\": 1, \"name\": \"Science education\", \"children\": [{\"count\": 0, \"name\": \"Science fairs\"}]}, {\"count\": 0, \"name\": \"Science policy and economics\"}, {\"count\": 0, \"name\": \"Technology regulations\"}]}]'"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Do full conversion and export"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Warning: it takes a minute."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plosthes_full_file = '../data/plosthes.2014-1.full.xlsx'\n",
      "\n",
      "# plos_tree = tree_from_spreadsheet(plosthes_full_file, df)\n",
      "\n",
      "# with open('../data/plos_full.json', 'wb') as f:\n",
      "#     json.dump(plos_tree, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "...\n",
      "\n",
      "> *And now for something completely different.*"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "How we made the actual PLOS Cloud Explorer web application"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*TBA*"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}