{
 "metadata": {
  "name": "",
  "signature": "sha256:5d1dc92aa17c245d09c8b64999ecb611ea15de4803fb18ba1d88453b9239ca7a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "PLOS Cloud Explorer: the process"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Batch Data Collection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We needed to collect article data from the PLOS API, which would include\n",
      "\n",
      "* article titles, authors, DOIs\n",
      "* publication date\n",
      "* abstracts\n",
      "* subject areas\n",
      "\n",
      "The code below will download all 100k+ articles with abstracts from the PLOS API, while respecting the limits on the frequency and number of API calls.\n",
      "\n",
      "We ended up downloading and saving data on articles within the subject area \"Information Technology.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### All imports are here:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import unicode_literals\n",
      "\n",
      "# Data analysis\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from numpy import nan\n",
      "from pandas import Series, DataFrame\n",
      "\n",
      "# You need an API Key for PLOS\n",
      "import settings\n",
      "\n",
      "# Interacting with API\n",
      "import requests\n",
      "import urllib\n",
      "import time\n",
      "from retrying import retry\n",
      "import os\n",
      "import random\n",
      "import json\n",
      "\n",
      "# Natural language processing\n",
      "import nltk\n",
      "from nltk.collocations import BigramCollocationFinder\n",
      "from nltk.metrics import BigramAssocMeasures\n",
      "from nltk.corpus import stopwords\n",
      "import string\n",
      "\n",
      "# For the IPython widgets:\n",
      "from IPython.display import display, Image, HTML, clear_output\n",
      "from IPython.html import widgets\n",
      "from jinja2 import Template"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## API Call Function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#adapted from Raymond's notebook\n",
      "\n",
      "def plos_search(q,start=0,rows=100,fl=None, extras=None):\n",
      "\n",
      "    BASE_URL = 'http://api.plos.org/search'\n",
      "    DEFAULT_FL = ('abstract','author',\n",
      "                  'id','journal','publication_date',\n",
      "                  'score','title_display', 'subject','subject_level')\n",
      "        #removed elements: eissn, article_type\n",
      "    \n",
      "    # fl indicates fields to return\n",
      "    # http://wiki.apache.org/solr/CommonQueryParameters#fl\n",
      "    \n",
      "    if fl is None:\n",
      "        fl_ = \",\".join(DEFAULT_FL)\n",
      "    else:\n",
      "        fl_ = \",\".join(fl)\n",
      "        \n",
      "    query = {'q':q,\n",
      "             'start':start,\n",
      "             'rows':rows,\n",
      "             'api_key':settings.PLOS_KEY,\n",
      "             'wt':'json',\n",
      "             'fl':fl_,\n",
      "             'fq': 'doc_type:full AND !article_type_facet:\"Issue Image\"'}\n",
      "    \n",
      "    if extras is not None:\n",
      "        query.update(extras)\n",
      "        \n",
      "    query_url = BASE_URL + \"?\" +urllib.urlencode(query)\n",
      "    \n",
      "    r = requests.get(query_url)\n",
      "    return r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Finding Parameters\n",
      "\n",
      "Need to make sure the calls do not exceed the following: \n",
      "\n",
      "* 7200 requests a day, 300 per hour, 10 per minute and allow 5 seconds for your search to return results.\n",
      "\n",
      "To be safe there will be a 15 second wait between each call:\n",
      "\n",
      "* 15 sec per call\n",
      "* 4 calls per minute\n",
      "* 240 calls per hour"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Call for all articles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = plos_search(q='subject:\"Information technology\"')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check the total number of articles with abstracts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tot_articles = r.json()['response']['numFound']\n",
      "tot_articles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With 118545 acticles total that means that we will have to perform 1,186 API requests at 100 articles per request.\n",
      "**At 240 requests per hour it should take about 5 hours to get all the data needed.**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Looping Function\n",
      "\n",
      "This function will call the plos_search function every 15 seconds while incrementing the start number so that all of the articles can be pulled."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@retry(wait='exponential_sleep', wait_exponential_multiplier=1000, wait_exponential_max=10000, stop='stop_after_attempt', stop_max_attempt_number=7)\n",
      "def data_request(end, start=0):\n",
      "    if os.path.exists('../data/abstract_df.pkl'):\n",
      "        df = pd.read_pickle('../data/abstract_df.pkl')\n",
      "        start = len(df)\n",
      "    current_end = end - start\n",
      "    loops = (current_end/100) + 1\n",
      "    for n in range(loops):\n",
      "        r = plos_search(q='subject:\"Information technology\"', start=start)\n",
      "        \n",
      "        #store data before next call\n",
      "        data = r.json()['response']['docs']\n",
      "        if start == 0:\n",
      "            abstract_df = pd.DataFrame(data)\n",
      "        else:\n",
      "            df = pd.read_pickle('../data/abstract_df.pkl')\n",
      "            abstract_df = df.append(pd.DataFrame(data))\n",
      "        \n",
      "        #increment the start for the next request\n",
      "        start+=100\n",
      "        \n",
      "        #every request pickle the dataframe\n",
      "        abstract_df.to_pickle('../data/abstract_df.pkl')\n",
      "        \n",
      "        #wait 15 seconds before the next loop\n",
      "        time.sleep(15)\n",
      "        \n",
      "    #pickle when finished\n",
      "    abstract_df.to_pickle('../data/abstract_df.pkl')\n",
      "    \n",
      "    return abstract_df\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can run the function inputing the tot_articles as the end parameter.\n",
      "\n",
      "**Make sure that the 'abstract_df.pkl' does not exist in the directory before running**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abstract_df = data_request(end=tot_articles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exploring Output\n",
      "\n",
      "> From here we can start running the code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abstract_df = pd.read_pickle('../data/abstract_df.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(list(abstract_df.author))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "1120"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print list(abstract_df.subject)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'/Computer and information sciences/Information technology/Data processing', u'/Computer and information sciences/Information technology/Data reduction', u'/Physical sciences/Mathematics/Statistics (mathematics)/Statistical methods', u'/Research and analysis methods/Mathematical and statistical techniques/Statistical methods', u'/Computer and information sciences/Information technology/Databases', u'/Physical sciences/Mathematics/Statistics (mathematics)/Statistical data', u'/Computer and information sciences/Computer architecture/User interfaces', u'/Medicine and health sciences/Infectious diseases/Infectious disease control', u'/Computer and information sciences/Data management']\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abstract_df.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>author</th>\n",
        "      <th>id</th>\n",
        "      <th>journal</th>\n",
        "      <th>publication_date</th>\n",
        "      <th>score</th>\n",
        "      <th>subject</th>\n",
        "      <th>title_display</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> [\\nPopulation structure can confound the ident...</td>\n",
        "      <td> [Jonathan Carlson, Carl Kadie, Simon Mallal, D...</td>\n",
        "      <td> 10.1371/journal.pone.0000591</td>\n",
        "      <td>                   PLoS ONE</td>\n",
        "      <td> 2007-07-04T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Biology and life sciences/Genetics/Phenotype...</td>\n",
        "      <td> Leveraging Hierarchical Population Structure i...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> [\\n        The discrimination of thatcherized ...</td>\n",
        "      <td> [Nick Donnelly, Nicole R Z\u00fcrcher, Katherine Co...</td>\n",
        "      <td> 10.1371/journal.pone.0023340</td>\n",
        "      <td>                   PLoS ONE</td>\n",
        "      <td> 2011-08-31T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Medicine and health sciences/Diagnostic medi...</td>\n",
        "      <td> Discriminating Grotesque from Typical Faces: E...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> [\\nInfluenza viruses have been responsible for...</td>\n",
        "      <td>           [Zhipeng Cai, Tong Zhang, Xiu-Feng Wan]</td>\n",
        "      <td> 10.1371/journal.pcbi.1000949</td>\n",
        "      <td> PLoS Computational Biology</td>\n",
        "      <td> 2010-10-07T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Biology and life sciences/Organisms/Viruses/...</td>\n",
        "      <td> A Computational Framework for Influenza Antige...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td> [\\n        Based on previous evidence for indi...</td>\n",
        "      <td> [Luis F H Basile, Jo\u00e3o R Sato, Milkes Y Alvare...</td>\n",
        "      <td> 10.1371/journal.pone.0059595</td>\n",
        "      <td>                   PLoS ONE</td>\n",
        "      <td> 2013-03-27T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Medicine and health sciences/Diagnostic medi...</td>\n",
        "      <td> Lack of Systematic Topographic Difference betw...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> [Objective: Herpes simplex virus type 2 (HSV-2...</td>\n",
        "      <td> [Alison C Roxby, Alison L Drake, Francisca Ong...</td>\n",
        "      <td> 10.1371/journal.pone.0038622</td>\n",
        "      <td>                   PLoS ONE</td>\n",
        "      <td> 2012-06-12T00:00:00Z</td>\n",
        "      <td> 0.443733</td>\n",
        "      <td> [/Medicine and health sciences/Women's health/...</td>\n",
        "      <td> Effects of Valacyclovir on Markers of Disease ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 8 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "                                             abstract  \\\n",
        "15  [\\nPopulation structure can confound the ident...   \n",
        "16  [\\n        The discrimination of thatcherized ...   \n",
        "17  [\\nInfluenza viruses have been responsible for...   \n",
        "18  [\\n        Based on previous evidence for indi...   \n",
        "19  [Objective: Herpes simplex virus type 2 (HSV-2...   \n",
        "\n",
        "                                               author  \\\n",
        "15  [Jonathan Carlson, Carl Kadie, Simon Mallal, D...   \n",
        "16  [Nick Donnelly, Nicole R Z\u00fcrcher, Katherine Co...   \n",
        "17            [Zhipeng Cai, Tong Zhang, Xiu-Feng Wan]   \n",
        "18  [Luis F H Basile, Jo\u00e3o R Sato, Milkes Y Alvare...   \n",
        "19  [Alison C Roxby, Alison L Drake, Francisca Ong...   \n",
        "\n",
        "                              id                     journal  \\\n",
        "15  10.1371/journal.pone.0000591                    PLoS ONE   \n",
        "16  10.1371/journal.pone.0023340                    PLoS ONE   \n",
        "17  10.1371/journal.pcbi.1000949  PLoS Computational Biology   \n",
        "18  10.1371/journal.pone.0059595                    PLoS ONE   \n",
        "19  10.1371/journal.pone.0038622                    PLoS ONE   \n",
        "\n",
        "        publication_date     score  \\\n",
        "15  2007-07-04T00:00:00Z  0.443733   \n",
        "16  2011-08-31T00:00:00Z  0.443733   \n",
        "17  2010-10-07T00:00:00Z  0.443733   \n",
        "18  2013-03-27T00:00:00Z  0.443733   \n",
        "19  2012-06-12T00:00:00Z  0.443733   \n",
        "\n",
        "                                              subject  \\\n",
        "15  [/Biology and life sciences/Genetics/Phenotype...   \n",
        "16  [/Medicine and health sciences/Diagnostic medi...   \n",
        "17  [/Biology and life sciences/Organisms/Viruses/...   \n",
        "18  [/Medicine and health sciences/Diagnostic medi...   \n",
        "19  [/Medicine and health sciences/Women's health/...   \n",
        "\n",
        "                                        title_display  \n",
        "15  Leveraging Hierarchical Population Structure i...  \n",
        "16  Discriminating Grotesque from Typical Faces: E...  \n",
        "17  A Computational Framework for Influenza Antige...  \n",
        "18  Lack of Systematic Topographic Difference betw...  \n",
        "19  Effects of Valacyclovir on Markers of Disease ...  \n",
        "\n",
        "[5 rows x 8 columns]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cleaning Output"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Testing retry decorator\n",
      "\n",
      "This is making sure that the retry decorator works"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@retry\n",
      "def do_something_unreliable():\n",
      "    if random.randint(0, 2) > 1:\n",
      "        raise IOError(\"Broken sauce, everything is hosed!!!111one\")\n",
      "    else:\n",
      "        return \"Awesome sauce!\"\n",
      "\n",
      "print do_something_unreliable()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Awesome sauce!\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Initial attempts to make word clouds using abstracts\n",
      "\n",
      "We wanted to use basic natural language processing (NLP) to make word clouds out of aggregated abstract text, and see how they change over time.\n",
      "\n",
      "NB: These examples use a previously collected dataset that's different and smaller than the one we generated above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Globally define a set of stopwords.\n",
      "stops = set(stopwords.words('english'))\n",
      "# We can add science-y stuff to it as well. Just an example:\n",
      "stops.add('conclusions')\n",
      "\n",
      "\n",
      "def wordify(abs_list, min_word_len=2):\n",
      "    '''\n",
      "    Convert the abstract field from PLoS API data to a filtered list of words.\n",
      "    '''\n",
      "\n",
      "    # The abstract field is a list. Make it a string.\n",
      "    text = ' '.join(abs_list).strip(' \\n\\t')\n",
      "\n",
      "    if text == '':\n",
      "        return nan\n",
      "\n",
      "    else:\n",
      "        # Remove punctuation & replace with space,\n",
      "        # because we want 'metal-contaminated' => 'metal contaminated'\n",
      "        # ...not 'metalcontaminated', and so on.\n",
      "        for c in string.punctuation:\n",
      "            text = text.replace(c, ' ')\n",
      "\n",
      "        # Now make it a Series of words, and do some cleaning.\n",
      "        words = Series(text.split(' '))\n",
      "        words = words.str.lower()\n",
      "        # Filter out words less than minimum word length.\n",
      "        words = words[words.str.len() >= min_word_len]\n",
      "        words = words[~words.str.contains(r'[^#@a-z]')]  # What exactly does this do?\n",
      "\n",
      "        # Filter out globally-defined stopwords\n",
      "        ignore = stops & set(words.unique())\n",
      "        words_out = [w for w in words.tolist() if w not in ignore]\n",
      "\n",
      "        return words_out\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load up some data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('biotech500.json', 'rb') as fp:\n",
      "    data = json.load(fp)\n",
      "    \n",
      "articles_list = data['response']['docs']\n",
      "articles = DataFrame(articles_list)\n",
      "articles = articles[articles['abstract'].notnull()]\n",
      "articles.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>article_type</th>\n",
        "      <th>author_display</th>\n",
        "      <th>eissn</th>\n",
        "      <th>id</th>\n",
        "      <th>journal</th>\n",
        "      <th>publication_date</th>\n",
        "      <th>score</th>\n",
        "      <th>title_display</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> [\\nThe objective of this paper is to assess th...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Latifah Amin, Md. Abul Kalam Azad, Mohd Hanaf...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0086174</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2014-01-29T00:00:00Z</td>\n",
        "      <td> 1.211935</td>\n",
        "      <td> Determinants of Public Attitudes to Geneticall...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> [\\n        Atrazine (ATZ) and S-metolachlor (S...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Cristina A. Viegas, Catarina Costa, Sandra An...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0037140</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2012-05-15T00:00:00Z</td>\n",
        "      <td> 1.119538</td>\n",
        "      <td> Does &lt;i&gt;S&lt;/i&gt;-Metolachlor Affect the Performan...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> [\\nDue to environmental persistence and biotox...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Yonggang Yang, Meiying Xu, Zhili He, Jun Guo,...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0070686</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2013-08-05T00:00:00Z</td>\n",
        "      <td> 1.119538</td>\n",
        "      <td> Microbial Electricity Generation Enhances Deca...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td> [\\n        Intensive use of chlorpyrifos has r...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Shaohua Chen, Chenglan Liu, Chuyan Peng, Hong...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0047205</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 2012-10-08T00:00:00Z</td>\n",
        "      <td> 1.119538</td>\n",
        "      <td> Biodegradation of Chlorpyrifos and Its Hydroly...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td> [Background: The complex characteristics and u...</td>\n",
        "      <td> Research Article</td>\n",
        "      <td> [Zhongbo Zhou, Fangang Meng, So-Ryong Chae, Gu...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0042270</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 2012-08-09T00:00:00Z</td>\n",
        "      <td> 0.989541</td>\n",
        "      <td> Microbial Transformation of Biomacromolecules ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 9 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "                                             abstract      article_type  \\\n",
        "7   [\\nThe objective of this paper is to assess th...  Research Article   \n",
        "16  [\\n        Atrazine (ATZ) and S-metolachlor (S...  Research Article   \n",
        "17  [\\nDue to environmental persistence and biotox...  Research Article   \n",
        "34  [\\n        Intensive use of chlorpyrifos has r...  Research Article   \n",
        "35  [Background: The complex characteristics and u...  Research Article   \n",
        "\n",
        "                                       author_display      eissn  \\\n",
        "7   [Latifah Amin, Md. Abul Kalam Azad, Mohd Hanaf...  1932-6203   \n",
        "16  [Cristina A. Viegas, Catarina Costa, Sandra An...  1932-6203   \n",
        "17  [Yonggang Yang, Meiying Xu, Zhili He, Jun Guo,...  1932-6203   \n",
        "34  [Shaohua Chen, Chenglan Liu, Chuyan Peng, Hong...  1932-6203   \n",
        "35  [Zhongbo Zhou, Fangang Meng, So-Ryong Chae, Gu...  1932-6203   \n",
        "\n",
        "                              id   journal      publication_date     score  \\\n",
        "7   10.1371/journal.pone.0086174  PLoS ONE  2014-01-29T00:00:00Z  1.211935   \n",
        "16  10.1371/journal.pone.0037140  PLoS ONE  2012-05-15T00:00:00Z  1.119538   \n",
        "17  10.1371/journal.pone.0070686  PLoS ONE  2013-08-05T00:00:00Z  1.119538   \n",
        "34  10.1371/journal.pone.0047205       NaN  2012-10-08T00:00:00Z  1.119538   \n",
        "35  10.1371/journal.pone.0042270       NaN  2012-08-09T00:00:00Z  0.989541   \n",
        "\n",
        "                                        title_display  \n",
        "7   Determinants of Public Attitudes to Geneticall...  \n",
        "16  Does <i>S</i>-Metolachlor Affect the Performan...  \n",
        "17  Microbial Electricity Generation Enhances Deca...  \n",
        "34  Biodegradation of Chlorpyrifos and Its Hydroly...  \n",
        "35  Microbial Transformation of Biomacromolecules ...  \n",
        "\n",
        "[5 rows x 9 columns]"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Applying this to the whole DataFrame of articles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles['words'] = articles.apply(lambda s: wordify(s['abstract'] + [s['title_display']]), axis=1)\n",
      "articles.drop(['article_type', 'score', 'title_display', 'abstract'], axis=1, inplace=True)\n",
      "articles.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>author_display</th>\n",
        "      <th>eissn</th>\n",
        "      <th>id</th>\n",
        "      <th>journal</th>\n",
        "      <th>publication_date</th>\n",
        "      <th>words</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> [Latifah Amin, Md. Abul Kalam Azad, Mohd Hanaf...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0086174</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2014-01-29T00:00:00Z</td>\n",
        "      <td> [objective, paper, assess, attitude, malaysian...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> [Cristina A. Viegas, Catarina Costa, Sandra An...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0037140</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2012-05-15T00:00:00Z</td>\n",
        "      <td> [atrazine, atz, metolachlor, met, two, herbici...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> [Yonggang Yang, Meiying Xu, Zhili He, Jun Guo,...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0070686</td>\n",
        "      <td> PLoS ONE</td>\n",
        "      <td> 2013-08-05T00:00:00Z</td>\n",
        "      <td> [due, environmental, persistence, biotoxicity,...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td> [Shaohua Chen, Chenglan Liu, Chuyan Peng, Hong...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0047205</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 2012-10-08T00:00:00Z</td>\n",
        "      <td> [intensive, use, chlorpyrifos, resulted, ubiqu...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td> [Zhongbo Zhou, Fangang Meng, So-Ryong Chae, Gu...</td>\n",
        "      <td> 1932-6203</td>\n",
        "      <td> 10.1371/journal.pone.0042270</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 2012-08-09T00:00:00Z</td>\n",
        "      <td> [background, complex, characteristics, unclear...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 6 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "                                       author_display      eissn  \\\n",
        "7   [Latifah Amin, Md. Abul Kalam Azad, Mohd Hanaf...  1932-6203   \n",
        "16  [Cristina A. Viegas, Catarina Costa, Sandra An...  1932-6203   \n",
        "17  [Yonggang Yang, Meiying Xu, Zhili He, Jun Guo,...  1932-6203   \n",
        "34  [Shaohua Chen, Chenglan Liu, Chuyan Peng, Hong...  1932-6203   \n",
        "35  [Zhongbo Zhou, Fangang Meng, So-Ryong Chae, Gu...  1932-6203   \n",
        "\n",
        "                              id   journal      publication_date  \\\n",
        "7   10.1371/journal.pone.0086174  PLoS ONE  2014-01-29T00:00:00Z   \n",
        "16  10.1371/journal.pone.0037140  PLoS ONE  2012-05-15T00:00:00Z   \n",
        "17  10.1371/journal.pone.0070686  PLoS ONE  2013-08-05T00:00:00Z   \n",
        "34  10.1371/journal.pone.0047205       NaN  2012-10-08T00:00:00Z   \n",
        "35  10.1371/journal.pone.0042270       NaN  2012-08-09T00:00:00Z   \n",
        "\n",
        "                                                words  \n",
        "7   [objective, paper, assess, attitude, malaysian...  \n",
        "16  [atrazine, atz, metolachlor, met, two, herbici...  \n",
        "17  [due, environmental, persistence, biotoxicity,...  \n",
        "34  [intensive, use, chlorpyrifos, resulted, ubiqu...  \n",
        "35  [background, complex, characteristics, unclear...  \n",
        "\n",
        "[5 rows x 6 columns]"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Doing some natural language processing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abs_df = DataFrame(articles['words'].apply(lambda x: ' '.join(x)).tolist(), columns=['text'])\n",
      "abs_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> objective paper assess attitude malaysian stak...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> atrazine atz metolachlor met two herbicides wi...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> due environmental persistence biotoxicity poly...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> intensive use chlorpyrifos resulted ubiquitous...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> background complex characteristics unclear bio...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "                                                text\n",
        "0  objective paper assess attitude malaysian stak...\n",
        "1  atrazine atz metolachlor met two herbicides wi...\n",
        "2  due environmental persistence biotoxicity poly...\n",
        "3  intensive use chlorpyrifos resulted ubiquitous...\n",
        "4  background complex characteristics unclear bio...\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are the most common paired words:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Common word pairs\n",
      "\n",
      "This section uses all words from abstracts to find the common word pairs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#include all words from abstracts for getting common word pairs\n",
      "words_all = pd.Series(' '.join(abs_df['text']).split(' '))\n",
      "words_all.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "study             56\n",
        "using             33\n",
        "two               32\n",
        "patients          31\n",
        "biodegradation    30\n",
        "non               29\n",
        "data              28\n",
        "three             28\n",
        "analysis          27\n",
        "compared          27\n",
        "soil              27\n",
        "new               27\n",
        "results           26\n",
        "species           25\n",
        "cell              25\n",
        "...\n",
        "engage             1\n",
        "thermal            1\n",
        "geochip            1\n",
        "dominant           1\n",
        "suggests           1\n",
        "third              1\n",
        "usually            1\n",
        "locomotion         1\n",
        "rpos               1\n",
        "scales             1\n",
        "prefer             1\n",
        "quite              1\n",
        "protocatechuate    1\n",
        "routine            1\n",
        "agr                1\n",
        "Length: 3028, dtype: int64"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "relevant_words_pairs = words_all.copy()\n",
      "relevant_words_pairs.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "study             56\n",
        "using             33\n",
        "two               32\n",
        "patients          31\n",
        "biodegradation    30\n",
        "non               29\n",
        "data              28\n",
        "three             28\n",
        "analysis          27\n",
        "compared          27\n",
        "soil              27\n",
        "new               27\n",
        "results           26\n",
        "species           25\n",
        "cell              25\n",
        "...\n",
        "engage             1\n",
        "thermal            1\n",
        "geochip            1\n",
        "dominant           1\n",
        "suggests           1\n",
        "third              1\n",
        "usually            1\n",
        "locomotion         1\n",
        "rpos               1\n",
        "scales             1\n",
        "prefer             1\n",
        "quite              1\n",
        "protocatechuate    1\n",
        "routine            1\n",
        "agr                1\n",
        "Length: 3028, dtype: int64"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bcf = BigramCollocationFinder.from_words(relevant_words_pairs)\n",
      "for pair in bcf.nbest(BigramAssocMeasures.likelihood_ratio, 30):\n",
      "    print ' '.join(pair)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synthetic biology\n",
        "spider silk\n",
        "es cell\n",
        "adjacent segment\n",
        "medical imaging\n",
        "dp dtmax\n",
        "security privacy\n",
        "industry backgrounds\n",
        "removal initiation\n",
        "uv irradiated\n",
        "gm salmon\n",
        "persistent crsab\n",
        "antimicrobial therapy\n",
        "limb amputation\n",
        "cellular phone\n",
        "wireless powered\n",
        "minimally invasive\n",
        "phone technology\n",
        "heavy metals\n",
        "battery powered\n",
        "composite mesh\n",
        "frequency currents\n",
        "genetically modified\n",
        "tissue engineering\n",
        "catheter removal\n",
        "acting reversible\n",
        "brassica napus\n",
        "brown streak\n",
        "quasi stiffness\n",
        "data code\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bcf.nbest(BigramAssocMeasures.likelihood_ratio, 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "[(u'synthetic', u'biology'),\n",
        " (u'spider', u'silk'),\n",
        " (u'es', u'cell'),\n",
        " (u'adjacent', u'segment'),\n",
        " (u'medical', u'imaging'),\n",
        " (u'dp', u'dtmax'),\n",
        " (u'security', u'privacy'),\n",
        " (u'industry', u'backgrounds'),\n",
        " (u'removal', u'initiation'),\n",
        " (u'uv', u'irradiated'),\n",
        " (u'gm', u'salmon'),\n",
        " (u'persistent', u'crsab'),\n",
        " (u'antimicrobial', u'therapy'),\n",
        " (u'limb', u'amputation'),\n",
        " (u'cellular', u'phone'),\n",
        " (u'wireless', u'powered'),\n",
        " (u'minimally', u'invasive'),\n",
        " (u'phone', u'technology'),\n",
        " (u'heavy', u'metals'),\n",
        " (u'battery', u'powered')]"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Making word clouds: select the top words\n",
      "\n",
      "Here, we takes only unique words from each abstract."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abs_set_df = DataFrame(articles['words'].apply(lambda x: ' '.join(set(x))).tolist(), columns=['text'])\n",
      "abs_set_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> among developed attitude paper identify accept...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> aquatic mineralization dose experiments still ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> mfc hypothesized distinctly results nitrogen s...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> fungal contaminant tcp accumulative gc morphol...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> origin humic mineralization show mainly result...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "                                                text\n",
        "0  among developed attitude paper identify accept...\n",
        "1  aquatic mineralization dose experiments still ...\n",
        "2  mfc hypothesized distinctly results nitrogen s...\n",
        "3  fungal contaminant tcp accumulative gc morphol...\n",
        "4  origin humic mineralization show mainly result...\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = pd.Series(' '.join(abs_set_df['text']).split(' '))\n",
      "words.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "study            38\n",
        "two              23\n",
        "using            21\n",
        "results          20\n",
        "three            20\n",
        "analysis         20\n",
        "compared         17\n",
        "used             16\n",
        "higher           16\n",
        "may              16\n",
        "non              15\n",
        "based            15\n",
        "significantly    14\n",
        "also             14\n",
        "however          14\n",
        "...\n",
        "septal             1\n",
        "recommendations    1\n",
        "genomes            1\n",
        "poking             1\n",
        "gck                1\n",
        "optimised          1\n",
        "varied             1\n",
        "counting           1\n",
        "monitoring         1\n",
        "malware            1\n",
        "tmc                1\n",
        "rape               1\n",
        "occur              1\n",
        "conversely         1\n",
        "cda                1\n",
        "Length: 3028, dtype: int64"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_words = words.value_counts().reset_index()\n",
      "top_words.columns = ['word', 'count']\n",
      "top_words.head(15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>word</th>\n",
        "      <th>count</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>         study</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>           two</td>\n",
        "      <td> 23</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>         using</td>\n",
        "      <td> 21</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>       results</td>\n",
        "      <td> 20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>         three</td>\n",
        "      <td> 20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>      analysis</td>\n",
        "      <td> 20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>      compared</td>\n",
        "      <td> 17</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>          used</td>\n",
        "      <td> 16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>        higher</td>\n",
        "      <td> 16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>           may</td>\n",
        "      <td> 16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>           non</td>\n",
        "      <td> 15</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>         based</td>\n",
        "      <td> 15</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> significantly</td>\n",
        "      <td> 14</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>          also</td>\n",
        "      <td> 14</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>       however</td>\n",
        "      <td> 14</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>15 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "             word  count\n",
        "0           study     38\n",
        "1             two     23\n",
        "2           using     21\n",
        "3         results     20\n",
        "4           three     20\n",
        "5        analysis     20\n",
        "6        compared     17\n",
        "7            used     16\n",
        "8          higher     16\n",
        "9             may     16\n",
        "10            non     15\n",
        "11          based     15\n",
        "12  significantly     14\n",
        "13           also     14\n",
        "14        however     14\n",
        "\n",
        "[15 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exporting word count data as CSV for D3 word-cloudification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# top_words.to_csv('../wordcloud2.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Initial word cloud results\n",
      "\n",
      "When we created the word clouds, we noticed something about the most common words in these article abstracts... \n",
      "\n",
      "![cloud](../wordcloud_example_old.jpg)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Change over time: working with article abstracts as time series data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_list = data['response']['docs']\n",
      "articles = DataFrame(articles_list)\n",
      "articles = articles[articles['abstract'].notnull()].ix[:,['abstract', 'publication_date']]\n",
      "articles.abstract = articles.abstract.apply(wordify, 3)\n",
      "articles = articles[articles['abstract'].notnull()]\n",
      "articles.publication_date = pd.to_datetime(articles.publication_date)\n",
      "articles.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>publication_date</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> [objective, paper, assess, attitude, malaysian...</td>\n",
        "      <td>2014-01-29</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> [atrazine, atz, metolachlor, met, two, herbici...</td>\n",
        "      <td>2012-05-15</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> [due, environmental, persistence, biotoxicity,...</td>\n",
        "      <td>2013-08-05</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td> [intensive, use, chlorpyrifos, resulted, ubiqu...</td>\n",
        "      <td>2012-10-08</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td> [background, complex, characteristics, unclear...</td>\n",
        "      <td>2012-08-09</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "                                             abstract publication_date\n",
        "7   [objective, paper, assess, attitude, malaysian...       2014-01-29\n",
        "16  [atrazine, atz, metolachlor, met, two, herbici...       2012-05-15\n",
        "17  [due, environmental, persistence, biotoxicity,...       2013-08-05\n",
        "34  [intensive, use, chlorpyrifos, resulted, ubiqu...       2012-10-08\n",
        "35  [background, complex, characteristics, unclear...       2012-08-09\n",
        "\n",
        "[5 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print articles.publication_date.min(), articles.publication_date.max()\n",
      "print len(articles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2008-04-30 00:00:00 2014-04-11 00:00:00\n",
        "57\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The time series spans ~9 years with 57 data points. **We need to resample!**\n",
      "\n",
      "There are probably many ways to do this..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_timed = articles.set_index('publication_date')\n",
      "articles_timed.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>publication_date</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2014-01-29</th>\n",
        "      <td> [objective, paper, assess, attitude, malaysian...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2012-05-15</th>\n",
        "      <td> [atrazine, atz, metolachlor, met, two, herbici...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013-08-05</th>\n",
        "      <td> [due, environmental, persistence, biotoxicity,...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2012-10-08</th>\n",
        "      <td> [intensive, use, chlorpyrifos, resulted, ubiqu...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2012-08-09</th>\n",
        "      <td> [background, complex, characteristics, unclear...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "                                                           abstract\n",
        "publication_date                                                   \n",
        "2014-01-29        [objective, paper, assess, attitude, malaysian...\n",
        "2012-05-15        [atrazine, atz, metolachlor, met, two, herbici...\n",
        "2013-08-05        [due, environmental, persistence, biotoxicity,...\n",
        "2012-10-08        [intensive, use, chlorpyrifos, resulted, ubiqu...\n",
        "2012-08-09        [background, complex, characteristics, unclear...\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using pandas time series resampling functions\n",
      "\n",
      "Using the `sum` aggregation method works because all the values were lists. The three abstracts published in 2013-05 were concatenated together (see below)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_monthly = articles_timed.resample('M', how='sum', fill_method='ffill', kind='period')\n",
      "articles_monthly.abstract = articles_monthly.abstract.apply(lambda x: np.nan if x == 0 else x)\n",
      "articles_monthly.fillna(method='ffill', inplace=True)\n",
      "articles_monthly.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>publication_date</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2008-04</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008-05</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008-06</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008-07</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008-08</th>\n",
        "      <td> [according, world, health, organization, repor...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "                                                           abstract\n",
        "publication_date                                                   \n",
        "2008-04           [according, world, health, organization, repor...\n",
        "2008-05           [according, world, health, organization, repor...\n",
        "2008-06           [according, world, health, organization, repor...\n",
        "2008-07           [according, world, health, organization, repor...\n",
        "2008-08           [according, world, health, organization, repor...\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Making a time slider for abstract text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "widgetmax = len(articles_monthly) - 1\n",
      "\n",
      "def textbarf(t): \n",
      "    html_template = \"\"\"\n",
      "    <style>\n",
      "    #textbarf {\n",
      "        display: block;\n",
      "        width: 666px;\n",
      "        padding: 23px;\n",
      "        background-color: #ddeeff;\n",
      "    }\n",
      "    </style>\n",
      "    <div id=\"textbarf\"> {{blargh}} </div>\"\"\"\n",
      "\n",
      "    blob = ' '.join(articles_monthly.ix[t]['abstract'])\n",
      "    html_src = Template(html_template).render(blargh=blob)\n",
      "    display(HTML(html_src))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "widgets.interact(textbarf,\n",
      "                 t=widgets.IntSliderWidget(min=0,max=widgetmax,step=1,value=42),\n",
      "                )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "    <style>\n",
        "    #textbarf {\n",
        "        display: block;\n",
        "        width: 666px;\n",
        "        padding: 23px;\n",
        "        background-color: #ddeeff;\n",
        "    }\n",
        "    </style>\n",
        "    <div id=\"textbarf\"> concerns regarding commercial release genetically engineered ge crops include naturalization introgression sexually compatible relatives transfer beneficial traits native weedy species hybridization date documented reports escape leading researchers question environmental risks biotech products study conducted systematic roadside survey canola brassica napus populations growing outside cultivation north dakota usa dominant canola growing region document presence two escaped transgenic genotypes well non ge canola provide evidence novel combinations transgenic forms wild results demonstrate feral populations large widespread moreover flowering times escaped populations well fertile condition majority collections suggest populations established persistent outside cultivation </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x10a3817d0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "<function __main__.textbarf>"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Transforming batch-collected data\n",
      "\n",
      "The desired data structure for article information is the following JSON object:\n",
      "\n",
      "```\n",
      "articles:\n",
      "  [ <doi>:\n",
      "      { author: [ ... ]\n",
      "        title:\n",
      "        journal:\n",
      "        publication_date: <yyyy>\n",
      "        subject: [ <full subject /-separated strings>, ... ]\n",
      "        subj_top: [ set of top levels of each subject ]\n",
      "        subj_leaf: [ set of last terms of each subject ]\n",
      "      },\n",
      "    ...\n",
      "  ]\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_pickle('../data/abstract_df.pkl')\n",
      "\n",
      "# Dropping abstract and score.\n",
      "df.drop(['abstract', 'score'], axis=1, inplace=True)\n",
      "df.set_index('id', inplace=True)\n",
      "df.columns = ['author', 'journal', 'publication_date', 'subject', 'title']\n",
      "df = df.reindex(columns=['author', 'title', 'journal', 'publication_date', 'subject'])\n",
      "# We just want the year.\n",
      "df.publication_date = df.publication_date.str[:4]\n",
      "\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_subj_top(subjects):\n",
      "    subj_top = set()\n",
      "    for s in subjects:\n",
      "        # the string gets split at its first character, so not [0] here:\n",
      "        subj_top.add(s.split('/')[1])\n",
      "    return subj_top\n",
      "\n",
      "def get_subj_leaf(subjects):\n",
      "    subj_top = set()\n",
      "    for s in subjects:\n",
      "        subj_top.add(s.split('/')[-1])\n",
      "    return subj_top"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['subj_top'] = df.subject.apply(get_subj_top)\n",
      "df['subj_leaf'] = df.subject.apply(get_subj_leaf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### If all is OK, export.."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# df.to_json(path_or_buf='../data/articles.json', orient='index', force_ascii=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}